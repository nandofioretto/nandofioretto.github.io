<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="Your description goes here" />
		<meta name="keywords" content="Ferdinando Fioretto,Nando Fioretto,Nando,Ferdinando,Fioretto,DCOP,Smart Grid,AI,GPU,Distributed" />
		<meta name="author" content="Ferdinando Fioretto" />
		<link rel="shortcut icon" href="img/su_icon.png">
		<link href="https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Quicksand|Work+Sans:400,700,800&display=swap" rel="stylesheet">
		<link rel="stylesheet" type="text/css" media="all" href="inland.css" />
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
		<script type="text/javascript" src="js/jquery.nivo.slider.js"></script>
		<title>Ferdinando Fioretto</title>
		<script>
			$(document).ready(function(){
				var moreText = "Show more",
				lessText = "Show less",
				moreButton = $("a.read_more");

				moreButton.click(
					function () {
						var $this = $(this);
						$this.text($this.text() == moreText ? lessText : moreText).next("div.more").slideToggle("fast");
					}
					);
			});
		</script>
		<script>
			$(document).ready(function(){
				var moreText = "Show more",
				lessText = "Show less",
				moreButton = $("a.read_more_title");
				moreButton.click(
					function () {
						$(this).nextAll("div.more").slideToggle("fast");
						var $show_text = $(this).nextAll("a.read_more");
						$show_text.text($show_text.text() == moreText ? lessText : moreText)
					}
					);
			});
		</script>
	</head>

	<body>
		<div id="wrapper960" class="clearfix">
			<div id="toplinks">
				<ul class="toplinks_links">
					<li>
						<a href='https://www.isye.gatech.edu'>
						<img align='center' src="img/su_logo.png"  height="40pt" style="margin:-14px -20px -14px 0px">
						</a>
					</li>
				</ul>
			</div>

			<div id="header" class="clearfix shadow">
				<div id="sitetitle" class="clearfix">
					<h1>Ferdinando Fioretto</h1>
				</div>

			<div id="nav" class="clearfix">
				<ul>
					<li><a href="index.html">Home</a></li>
					<!-- <li><a href="news.html">News</a></li> -->
					<!-- <li><a class="current" href="research.html">Research</a></li> -->
					<li><a href="publications.html">Publications</a></li>
					<li><a href="people.html">People</a></li>
					<li><a href="teaching.html">Teaching</a></li>
					<li><a href="index.html#contacts">Contacts</a></li>
				</ul>
			</div>
		</div>

			<!-- HEAD -->
			<div id="content" class="clearfix shadow">
				<h2> Private AI </h2>
			</div>

		<div id="content">
		<table style="height: 220px;" width="100%">
			<tr>
				<td style="vertical-align: top;" align="justified">
					<p style="text-align: justify; padding-bottom: 0px">
					Every day, massive amounts of data are collected, shared, and used as input to machine learning and sophisticated optimization algorithms,  providing valuable benefits to the society. However, sensitive properties can be inferred from these data, and inappropriate use might result in social and financial harm to the individuals. Managing privacy is a technical and societal challenge that must be carefully addressed to realize the promise of an ethical data-driven decision making.
					<br>
					<a href="https://en.wikipedia.org/wiki/Differential_Privacy">Differential privacy</a>  (DP) is a property of an algorithm ensuring a strong privacy protection for individuals participating in a data analysis task.
					A DP algorithm protects an individual's data by injecting randomized noise into it. While such a process ensures privacy, it also impacts the quality of data analysis, creating a tradeoff between utility and privacy. Thus, a critical aspect of privacy research focuses on how to share sensitive data limiting disclosure while ensuring sufficient utility.
					<br>
					The main direction of my research in privacy is concerned with the protection of sensitive users' data for large-scale optimization and machine learning models while preserving the salient features of the application of interest.
 				</p>
				</td>
				<td style="vertical-align: top; padding-left: 10px"  width="200">
					<br>
					<img src="img/rs_privacy2.jpg" alt="Privacy" width="200" />
				</td>

			</tr>
		</table>

<!-- Collaborators -->
		<h3>Students and Collaborators</h3>
		<ul>
			<li><a href="http://pwp.gatech.edu/pascal-van-hentenryck/">Pascal Van Hentenryck</a>, Georgia Institute of Technology</li>
			<li><a href="#">Chansoo Lee</a>, Google</li>
			<li><a href="https://arc-ts.umich.edu/staff-member/eric-boyd/">Eric Boyd</a>, University of Michigan</li>
			<li><a href="https://sites.google.com/view/lesiamitridati">Lesia Mitridati</a>
			<li><a href="https://www.tmak.info/">Terrence W.K. Mak</a>, Georgia Institute of Technology</li>
			<li><a href="http://www-personal.umich.edu/~lynshi/">Lyndon Shi</a>, University of Michigan</li>
		</ul>

<!-- Publications -->
		<h3>Recent Publications</h3>
		<ul>

			<li name="pscc20" id="pscc20">
				Terrence W.K. Mak, <strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
				<a class="read_more_title">&quot;Privacy-Preserving Obfuscation for Distributed Power Systems&quot;</a>.
				<em>PSCC</em> (to appear), 2020.
				<br>
				<span class="paper_links">
					<em style="color: #16A085";>Downloads</em>:
					<a href="files/papers/pscc20.pdf"  target="blank">[pdf]</a>
					<a href="files/bibtex/pscc20-bib.txt" target="blank">[BibTex]</a>
					| 
					<em style="color: #16A085";>Links</em>:
					<a href="#" target="">[web]</a>
					<a href="mailto:fioretto@gatech.edu?subject=Code request for paper id [pscc20]
					&body=Hi,  I would like to request code and results associated to your paper ID: pscc20. Thanks!
					&cc=wmak@gatech.edu,pvh@isye.gatech.edu">[request code]</a>
				</span>
				<a class="read_more">Show more</a>
				<div class="more abstract bg-blue">
					<strong><em>Abstract</em></strong>:
					This paper considers the problem of releasing privacy-preserving 
					load data of a decentralized operated power system. The paper 
					focuses on data used to solve Optimal Power Flow (OPF) problems 
					and proposes a distributed algorithm that complies with the notion 
					of Differential Privacy, a strong privacy framework used to bound 
					the risk of re-identification. The problem is challenging since 
					the application of traditional differential privacy mechanisms to the 
					load data fundamentally changes the nature of the underlying 
					optimization problem and often leads to severe feasibility issues. 
					The proposed differentially private distributed algorithm is based on 
					the Alternating Direction Method of Multipliers (ADMM) and guarantees 
					that the released privacy-preserving data retains high fidelity 
					and satisfies the AC power flow constraints. Experimental results on 
					a variety of OPF benchmarks demonstrate the effectiveness of the approach.
				</div>
			</li>
		<li name="arxiv20a" id="arxiv20a">
			<strong>Ferdinando Fioretto</strong>, Terrence W.K. Mak, Pascal Van Hentenryck.
			<a class="read_more_title">"Bilevel Optimization for Differentially Private Optimization"</a>.
			<em>CoRR abs/2001.09508 [math.OC/cs.AI,cs.CR]</em>, 2020.
			<br>
			<span class="paper_links">
				<em style="color: #16A085";>Downloads</em>:
				<a href="files/papers/arxiv20a.pdf"  target="blank">[pdf]</a>
				<a href="files/bibtex/arxiv20a-bib.txt" target="blank">[BibTex]</a>
				| 
				<em style="color: #16A085";>Links</em>:
				<a href="https://arxiv.org/abs/2001.09508" target="">[web]</a>
				<a href="mailto:fioretto@gatech.edu?subject=Code request for paper id [arxiv20a]
				&body=Hi,  I would like to request code and results associated to your paper ID: arxiv20a. Thanks!
				&cc=wmak@gatech.edu,pvh@isye.gatech.edu">[request code]</a>
			</span>
			<a class="read_more">Show more</a>
			<div class="more abstract bg-blue">
				<strong><em>Abstract</em></strong>:
				This paper studies how to apply differential privacy to constrained optimization problems whose inputs are sensitive. This task raises significant challenges since random perturbations of the input data often render the constrained optimization problem infeasible or change significantly the nature of its optimal solutions. To address this difficulty, this paper proposes a bilevel optimization model that can be used as a post-processing step: It redistributes the noise introduced by a differentially private mechanism optimally while restoring feasibility and near-optimality. The paper shows that, under a natural assumption, this bilevel model can be solved efficiently for real-life large-scale nonlinear nonconvex optimization problems with sensitive customer data. The experimental results demonstrate the accuracy of the privacy-preserving mechanism and showcase significant benefits compared to standard approaches.
			</div>
		</li>


		<li name="ieeetps19" id="ieeetps19">
		Terrence W.K. Mak, <strong>Ferdinando Fioretto</strong>, Lyndon Shi, Pascal Van Hentenryck.
		<a class="read_more_title">&quot;Privacy-Preserving Power System Obfuscation: A Bilevel Optimization Approach&quot;</a>.
		In <em>IEEE Transactions on Power Systems</em>, (in press).
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>:
			<a href="files/papers/ieeetps19.pdf"  target="blank">[pdf]</a>
			<a href="files/bibtex/ieeetps19-bib.txt" target="blank">[BibTex]</a>
			| 
<!-- 				<em style="color: #16A085";>Links</em>:
			<a href="">[web]</a>
-->			</span>

		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			This paper considers the problem of releasing optimal power flow (OPF) test cases that preserve the privacy of customers (loads) using the notion of Differential Privacy. It is motivated by the observation that traditional differential privacy algorithms are not suitable for releasing privacy preserving OPF test cases: The added noise fundamentally changes the nature of the underlying optimization and often leads to test cases with no solutions. To remedy this limitation, the paper introduces the OPF Load Indistinguishability (OLI) problem, which guarantees load privacy while satisfying the OPF constraints and remaining close to the optimal dispatch cost. The paper introduces an exact mechanism, based on bilevel optimization, as well as three mechanisms that approximate the OLI problem accurately. These mechanisms enjoy desirable theoretical properties, and the computational experiments show that they produce orders of magnitude improvements over standard approaches on an extensive collection of test cases.
		</div>
		</li>

		<li name="cp19" id="cp19">
		<strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
		<a class="read_more_title">
			&quot;Differential Privacy of Hierarchical Census Data: An Optimization Approach&quot;
		</a>.
		In Proceedings of the <em>International Conference on Principles and Practice of Constraint Programming (CP)</em>,  2019.
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>: 
			To appear
			<a href="files/papers/cp19.pdf"  target="blank">[pdf]</a>
			<!-- <a href="#"  target="blank">[slides]</a> -->
			<a href="files/bibtex/cp19-bib.txt" target="blank">[BibTex]</a>
			| 
			<em style="color: #16A085";>Links</em>:
			<a href="http://cp2019.a4cp.org/" target="blank">[web]</a>	
			<a href="mailto:fioretto@gatech.edu?subject=Code request for
			 paper id [cp19]
			&body=Hi,  I would like to request code and results associated to your paper ID: cp19. Thanks!
			&cc=pvh@isye.gatech.edu">[request code]</a>
		</span>
		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			This paper is motivated by applications of a Census Bureau interested in releasing aggregate socio-economic 
			data about a large population without revealing sensitive information. The released information can be the 
			number of individuals living alone, the number of cars they own, or their salary brackets. Recent events have 
			identified some of the privacy challenges faced by these organizations. To address them, this paper presents 
			a novel differential-privacy mechanism for releasing hierarchical counts of individuals satisfying a given 
			property. The counts are reported at multiple granularities (e.g., the national, state, and county levels) 
			and must be consistent across levels. The core of the mechanism is an optimization model that redistributes 
			the noise introduced to attain privacy in order to meet the consistency constraints between the hierarchical 
			levels. The key technical contribution of the paper shows that this optimization problem can be solved in 
			polynomial time by exploiting the structure of its cost functions. Experimental results on very large, real 
			datasets show that the proposed mechanism provides improvements up to two orders of magnitude in terms of 
			computational efficiency and accuracy with respect to other state-of-the-art techniques.
		</div>
		</li>

		<li name="ieeetsg19" id="ieeetsg19">
		<strong>Ferdinando Fioretto</strong>, Terrence W.K. Mak, Pascal Van Hentenryck.
		<a class="read_more_title">&quot;Differential Privacy for Power Grid Obfuscation&quot;</a>.
		In <em>IEEE Transactions on Smart Grids</em>, (in press).
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>:
			<a href="files/papers/ieeetsg19.pdf"  target="blank">[pdf]</a>
			<a href="files/bibtex/ieeetsg19-bib.txt" target="blank">[BibTex]</a>
			| 
<!-- 				<em style="color: #16A085";>Links</em>:
			<a href="">[web]</a>
-->			</span>

		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			The availability of high-fidelity energy networks brings significant value to academic and commercial research. However, such releases also raise fundamental concerns related to privacy and security as they can reveal sensitive commercial information and expose system vulnerabilities. This paper investigates how to release the data for power networks where the parameters of transmission lines and transformers are obfuscated. It does so by using the framework of Differential Privacy (DP), that provides strong privacy guarantees and has attracted significant attention in recent years. Unfortunately, simple DP mechanisms often result in AC-infeasible networks. To address these concerns, this paper presents a novel differentially private mechanism that guarantees AC-feasibility and largely preserves the fidelity of the obfuscated power network. Experimental results also show that the obfuscation significantly reduces the potential damage of an attack carried by exploiting the released dataset.
		</div>
		</li>

		<li name="jair19" id="jair19">
		<strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
		<a class="read_more_title">"OptStream: Releasing Time Series Privately"</a>.
		In <em>Journal of Artificial Intelligence Research (JAIR)</em>, 2019.
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>:
			<a href="files/papers/jair19.pdf"  target="blank">[pdf]</a>
			<a href="files/bibtex/jair19-bib.txt" target="blank">[BibTex]</a>
			| 
			<em style="color: #16A085";>Links</em>:
			<a href="http://www.jair.org/vol/vol65.html">[web]</a>
		</span>

		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			Many applications of machine learning and optimization operate on data streams. While these datasets are fundamental to fuel decision-making algorithms, often they contain sensitive information about individuals, and their usage poses significant privacy risks. Motivated by an application in energy systems, this paper presents OptStream, a novel algorithm for releasing differentially private data streams under the w-event model of privacy. OptStream is a 4-step procedure consisting of sampling, perturbation, reconstruction, and post-processing modules. First, the sampling module selects a small set of points to access in each period of interest. Then, the perturbation module adds noise to the sampled data points to guarantee privacy. Next, the reconstruction module reassembles non-sampled data points from the perturbed sample points. Finally, the post-processing module uses convex optimization over the privacy-preserving output of the previous modules, as well as the privacy-preserving answers of additional queries on the data stream, to improve accuracy by redistributing the added noise. OptStream is evaluated on a test case involving the release of a real data stream from the largest European transmission operator. Experimental results show that OptStream may not only improve the accuracy of state-of-the-art methods by at least one order of magnitude but also supports accurate load forecasting on the privacy-preserving data.
		</div>
		</li>

		<li name="ijcai19" id="ijcai19">
		<strong>Ferdinando Fioretto</strong>, Terrence W.K. Mak, Pascal Van Hentenryck.
		<a class="read_more_title">
			&quot;Privacy-Preserving Obfuscation of Critical Infrastructure Networks&quot;
		</a>.
		In Proceedings of the <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>,  2019.
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>: 
			To appear
			<a href="files/papers/ijcai19.pdf"  target="blank">[pdf]</a>
			<!-- <a href="#"  target="blank">[slides]</a> -->
			<a href="files/bibtex/ijcai19-bib.txt" target="blank">[BibTex]</a>
			| 
			<em style="color: #16A085";>Links</em>:
			<a href="https://ijcai19.org/" target="blank">[web]</a>	
			<a href="mailto:fioretto@umich.edu?subject=Code request for
			 paper id [ijcai19]
			&body=Hi,  I would like to request code and results associated to your paper ID: ijcai19. Thanks!
			&cc=wmak@gatech.edu,pvh@isye.gatech.edu">[request code]</a>
		</span>
		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			The paper studies how to release data about a critical infrastructure network (e.g., the power network or a transportation network) without disclosing sensitive information that can be exploited by malevolent agents, while preserving the realism of the network. It proposes a novel obfuscation mechanism that combines several privacy-preserving building blocks with a bi-level optimization model to significantly improve accuracy. The obfuscation is evaluated for both realism and privacy properties on real energy and transportation networks. Experimental results show the obfuscation mechanism substantially reduces the potential damage of an attack exploiting the released data to harm the real network.
		</div>
		</li>


		<li name="aamas19" id="aamas19">
		<strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
		<a class="read_more_title">""Privacy-Preserving Federated Data Sharing"</a>.
		In Proceedings of the <em>International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</em>,  2019.
		<br>
		<span class="paper_links">
			<em style="color: #16A085";>Downloads</em>:
			<a href="files/papers/aamas19.pdf"  target="blank">[pdf]</a>
			<a href="files/talks/aamas19-slides.pdf" target="blank">[slides]</a>
			<a href="files/bibtex/aamas19-bib.txt" target="blank">[BibTex]</a>
			| 
			<em style="color: #16A085";>Links</em>:
			<a href="https://dl.acm.org/citation.cfm?id=3331750" target="blank">[web]</a>
		</span>
		<a class="read_more">Show more</a>
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			Consider a set of agents with sensitive datasets who are interested
			 in the same prediction task and would like to share their datasets
			 without revealing private information.  For instance, the agents may
			 be hospitals with their own historical databases and the task may be
			 the diagnosis of a rare form of disease. This paper investigates
			 whether sharing privacy-preserving versions of these datasets may
			 improve the agent predictions. It proposes a Multi-agent
			 Privacy-preserving Data Sharing (MPDS) protocol that each agent can
			 run locally and produce a privacy-preserving version of its original
			 dataset. The MPDS protocol is evaluated on several standard
			 prediction tasks and the experimental results demonstrate the potential 
			 of sharing privacy-preserving datasets to produce accurate predictors.
		</div>
		</li>


		<li name="arxiv19a" id="arxiv19a">
			<strong>Ferdinando Fioretto</strong>, Terrence W.K. Mak, Pascal Van Hentenryck.
			<a class="read_more_title">"Differential Privacy for Power Grid Obfuscation"</a>.
			<em>CoRR abs/1901.06949 [cs.AI]</em>, 2019.
			<br>
			<span class="paper_links">
				<em style="color: #16A085";>Downloads:</em>
				<a href="files/papers/arxiv19a.pdf"  target="blank">[pdf]</a>
				<a href="files/bibtex/arxiv19a-bib.txt" target="blank">[BibTex]</a>
				| 
				<em style="color: #16A085";>Links:</em>
				<a href="https://arxiv.org/abs/1901.06949" target="">[web]</a>
				<a href="mailto:fioretto@gatech.edu?subject=Code request for paper id [arxiv19a]
				&body=Hi,  I would like to request code and results associated to your paper ID: arxiv19a. Thanks!
				&cc=wmak@gatech.edu,pvh@isye.gatech.edu">[request code]</a>
			</span>
			<a class="read_more">Show more</a>
			<div class="more abstract bg-blue">
				<strong><em>Abstract</em></strong>:
				The availability of high-fidelity energy networks brings significant value to academic and commercial research. 
				However, such releases also raise fundamental concerns related to privacy and security as they can reveal sensitive 
				commercial information and expose system vulnerabilities. This paper investigates how to release power networks where 
				the parameters of transmission lines and transformers are obfuscated. It does so by using the framework of Differential 
				Privacy (DP), that provides strong privacy guarantees and has attracted significant attention in recent years. 
				Unfortunately, simple DP mechanisms often result in AC-infeasible networks. To address these concerns, this paper presents 
				a novel differential privacy mechanism that guarantees AC-feasibility and largely preserves the fidelity of the obfuscated 
				network. Experimental results also show that the obfuscation significantly reduces the potential damage of an attacker 
				exploiting the release of the dataset.
			</div>
			</li>

			<li name="aamas18" id="aamas18">
				<strong>Ferdinando Fioretto</strong>, Chansoo Lee, Pascal Van Hentenryck.
				<a class="read_more_title">"Constrained-based Differential Privacy for Private Mobility"</a>.
				In Proceedings of the <em>International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</em>,  2018.
				<br>
				<span class="paper_links">
					<em style="color: #16A085";>Downloads:</em>
					<a href="files/papers/aamas18.pdf"  target="blank">[pdf]</a>
					<a href="files/talks/aamas18-slides.pdf"  target="blank">[slides]</a>
					<a href="files/bibtex/aamas18-bib.txt" target="blank">[BibTex]</a>
					| 
					<em style="color: #16A085";>Links:</em>
					<a href="http://celweb.vuse.vanderbilt.edu/aamas18/acceptedPapers/" target="blank">[web]</a>
					<a href="mailto:fioretto@umich.edu?subject=Code request for paper id [aamas18]
					&body=Hi,  I would like to request code and results associated to your paper ID: aamas18. Thanks!
					&cc=pvanhent@umich.edu">[request code]</a>
				</span>
				<a class="read_more">Show more</a>
				<div class="more abstract bg-blue">
					<strong><em>Abstract</em></strong>:
					Ubiquitous mobile and wireless communication systems have the potential to revolutionize transportation systems, making accurate mobility traces and activity-based patterns available to optimize their design and operations. It also poses significant privacy risks, potentially revealing highly sensitive personal information.  This paper studies the use of <em>differential privacy</em> to release mobility data that can be used for smart transportation systems. It shows that existing approaches do not provide the desired fidelity for practical uses. To remedy this critical limitation, the paper proposes the idea of <em>optimization-based differential privacy</em> that casts the production of a private dataset as an optimization problem that minimizes the impact of added Laplacian noise on the algorithmic task at hand. When applied to a city-level multi-modal transit system, experimental results show that the design and operations of the transportation system have similar performance measures when optimized over the real and private datasets. The results also indicate that optimization-based differential privacy may improve the accuracy of state-of-art privacy methods by an order of magnitude.
				</div>
			</li>
			<li name="cpaior18" id="cpaior18">
				<strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
				<a class="read_more_title">"Constrained-based Differential Privacy: Releasing Optimal Power Flow Benchmarks Privately"</a>.
				In Proceedings of the <em>International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research (CPAIOR)</em>,  2018.
				<br>
				<span class="paper_links">
					<em style="color: #16A085";>Downloads:</em>
					<a href="files/papers/cpaior18.pdf"  target="blank">[pdf]</a>
					<a href="files/talks/cpaior18-slides.pdf"  target="blank">[slides]</a>
					<a href="files/bibtex/cpaior18-bib.txt" target="blank">[BibTex]</a>
					| 
					<em style="color: #16A085";>Links:</em>
					<a href="https://sites.google.com/view/cpaior2018/program/schedule" target="blank">[web]</a>
					<a href="mailto:fioretto@umich.edu?subject=Code request for paper id [cpaior18]
					&body=Hi,  I would like to request code and results associated to your paper ID: cpaior18. Thanks!
					&cc=pvanhent@umich.edu">[request code]</a>
				</span>
				<a class="read_more">Show more</a>
				<div class="more abstract bg-blue">
					<strong><em>Abstract</em></strong>:
					This paper considers the problem of releasing optimal power flow benchmarks that maintain the privacy of customers (loads) using the notion of <em>Differential Privacy</em>.  It is motivated by the observation that traditional differential-privacy mechanisms are not accurate enough: The dded noise fundamentally changes the nature of the underlying optimization and often leads to test cases with no solution. To remedy this limitation, the paper introduces the framework of <em>Constraint-Based Differential Privacy (CBDP)</em> that leverages the post-processing immunity of differential privacy to improve the accuracy of traditional mechanisms. More precisely, CBDP solves an optimization problem to satisfies the problem-specific constraints by redistributing the noise. The paper shows that CBDP enjoys desirable theoretical properties and produces orders of magnitude improvements on the largest set of test cases available.
				</div>
			</li>

			<li name="arxiv18" id="arxiv18">
				<strong>Ferdinando Fioretto</strong>, Pascal Van Hentenryck.
				<a class="read_more_title">"Differential Private Stream Processing of Energy Consumption"</a>.
				<em>CoRR abs/1808.01949</em>, 2018.
				<br>
				<span class="paper_links">
					<em style="color: #16A085";>Downloads:</em>
					<a href="files/papers/arxiv18.pdf"  target="blank">[pdf]</a>
					<!-- <a href="files/talks/optmas18-slides.pdf"  target="blank">[slides]</a> -->
					<a href="files/bibtex/arxiv18-bib.txt" target="blank">[BibTex]</a>
					| 
					<em style="color: #16A085";>Links:</em>
					<a href="https://arxiv.org/abs/1808.01949" target="">[web]</a>
					<!-- <a href="https://github.com/nandofioretto/SHDS_dataset"  target="blank">[github]</a> -->
					<!-- <a href="mailto:fioretto@umich.edu?subject=Code request for paper id [optmas18]
					&body=Hi,  I would like to request code and results associated to your paper ID: optmas18. Thanks!
					&cc=hongx@usc.edu">[request code]</a> -->
				</span>

				<a class="read_more">Show more</a>
				<div class="more abstract bg-blue">
					<strong><em>Abstract</em></strong>:
					A number of applications benefit from continuously releasing streams of personal data statistics. The process, however, poses significant privacy risks. Motivated by an application in energy systems, this paper presents OptStream, a novel algorithm for releasing differential private data streams. OptStream is a 4-step procedure consisting of sampling, perturbation, reconstruction, and post-processing modules. The sampling module selects a small set of points to access privately in each period of interest, the perturbation module adds noise to the sampled data points to guarantee privacy, the reconstruction module re-assembles the non-sampling data points from the perturbed sampled points, and the post-processing module uses convex optimization over the private output of the previous modules, as well as the private answers of additional queries on the data stream, to ensure consistency of the data's salient features. OptStream is used to release a real data stream from the largest transmission operator in Europe. Experimental results show that OptStream not only improves the accuracy of the state-of-the-art by at least one order of magnitude on this application domain, but it is also able to ensure accurate load forecasting based on the private data.
				</div>
			</li>
		</ul>

		</div>

		<!-- Footer -->
		<div id="footer" class="shadow">
		  <p>&copy; 2018 - 2020 Ferdinando Fioretto | <a href="http://andreasviklund.com/templates/inland/">Template design</a> by <a href="http://andreasviklund.com/">andreasviklund.com</a><br /></p>
		  <p> Last Update: Mar. 2020
		</div>
	</div>

	<script type="text/javascript">
				$(window).load(function() {
					$('#slider').nivoSlider();
				});
	</script>

	<script>w3.includeHTML();</script>

	</body>
</html>
