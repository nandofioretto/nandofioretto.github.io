<!-- constraints17 -->
<li name="constraints17" id="constraints17">
	<strong>Ferdinando Fioretto</strong>, Enrico Pontelli, William Yeoh, Rina Dechter. 
	<a class="read_more_title">"Accelerating Exact and Approximate Inference for (Distributed) Discrete Optimization with GPUs"</a>.
	In <em>Constraints</em>, 2017.
	<br>
	<span class="paper_links">
		Downloads:
		<a href="files/papers/constraints17.pdf"  target="blank">[pdf]</a>  
		<a href="files/bibtex/constraints17-bib.txt" target="blank">[BibTex]</a> 
		| Links:
		<a href="" target="">[web]</a>
		<a href="https://github.com/nandofioretto/GpuBE"  target="blank">[github]</a>
		<!-- <a href="mailto:fioretto@umich.edu?subject=Code request for paper id [constraints17] -->
			<!-- 	 &body=Hi,  I would like to request the code associated to your paper ID: constraints17. Thanks! -->
			<!-- 	 &cc=wyeoh@cs.nmsu.edu,epontell@cs.nmsu.edu,dechter@ics.uci.edu">[request code]</a> -->
		</span>
		<a class="read_more">Show more</a> 
		<div class="more abstract bg-blue">
			<strong><em>Abstract</em></strong>:
			Discrete optimization is a central problem in artificial intelligence. The optimization of the aggregated cost of a network of 
			cost functions arises in a variety of problems including Weighted Constraint Programs (WCSPs), Distributed Constraint Optimization (DCOP), 
			as well as optimization in stochastic variants such as the tasks of finding the most probable explanation (MPE) in belief networks. 
			Inference-based algorithms are powerful techniques for solving discrete optimization problems, which can be used independently or in 
			combination with other techniques. However, their applicability is often limited by their compute intensive nature and their space requirements.
			This paper proposes the design and implementation of a novel inference-based technique, which exploits modern massively parallel architectures, 
			such as those found in Graphical Processing Units (GPUs), to speed up the resolution of exact and approximated inference-based algorithms 
			for discrete optimization. The paper studies the proposed algorithm in both centralized and distributed optimization contexts.
			The paper demonstrates that the use of GPUs provides significant advantages in terms of runtime and scalability, achieving up to two orders of 
			magnitude in speedups and showing a considerable reduction in execution time (up to 345 times faster) with respect to a sequential version.
		</div>
	</li>