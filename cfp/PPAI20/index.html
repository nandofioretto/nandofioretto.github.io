<!DOCTYPE HTML>
<html>
	<head>
		<title>PPAI 2020</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=0.75" />
		<meta name="description" content="PPAI 2020 Home Page" />
		<meta name="keywords" content="PPAI 20, Privacy Preserving AI 2020, AAAI" />
		<meta name="author" content="Ferdinando Fioretto" />
		<link rel="stylesheet" href="assets/css/main.css" />
	
		<style type="text/css">
		 .tab { margin-left: 18px; }
		</style>
	</head>
	<body>
	<div id="wrapper">

	<header id="header" class="alt">
<!--<span class="logo"><img src="images/aamas19_logo.png" alt=""  width="265"/></span> -->
	<h1>The AAAI Workshop on <br>Privacy-Preserving Artificial Intelligence</h1>
	<h2><strong>@AAAI-20</strong></h2>
	</header>

	<!-- Nav -->
	<nav id="nav">
	<ul>
		<li><a href="#scope" class="active">Scope</a></li>
		<li><a href="#submission">Submission</a></li>
		<li><a href="#dates">Important Dates</a></li>
		<li><a href="#papers">Accepted Papers</a></li>
		<li><a href="#program">Program</a></li>
		<li><a href="#committee">Program Committee</a></li>
		<li><a href="#contact">Contact</a></li>
	</ul>
	</nav>

	<!-- Main -->
	<div id="main">

	<section id="scope" class="main">
	<div class="spotlight">
	The availability of massive amounts of data, coupled with high-performance cloud computing platforms, has driven significant progress in artificial intelligence and, in particular, machine learning and optimization. Indeed, much scientific and technological growth in recent years, including in computer vision, natural language processing, transportation, and health, has been driven by large-scale data sets which provide a strong basis to improve existing algorithms and develop new ones. However, due to their large-scale and longitudinal collection, archiving these data sets raise significant privacy concerns. They often reveal sensitive personal information that can be exploited, without the knowledge and/or consent of the involved individuals, for various purposes including monitoring, discrimination, and illegal activities. 
 	<br>

	The goal of the AAAI-20 Workshop on Privacy-Preserving Artificial Intelligence is to provide a platform for researchers to discuss problems and present solutions related to privacy issues arising within AI applications. The workshop will focus on both theoretical and practical challenges arising in the design of privacy-preserving AI systems and algorithms. It will place particular emphasis on algorithmic approaches to protect data privacy in the context of learning, optimization, and decision making that raise fundamental challenges for existing technologies. Additionally, it will welcome algorithms and frameworks to release privacy-preserving benchmarks and datasets. 
	</div>

	<h2>Topics of Interest</h2>
	We invite paper submissions on the following (and related) topics:
	<ul>
	<li>Applications of privacy-preserving AI systems</li>
	<li>Architectures and privacy-preserving learning protocols </li>
	<li>Constrained-based approaches to privacy</li>
	<li>Differential privacy: theory and applications</li>
	<li>Distributed privacy-preserving algorithms</li>
	<li>Human-aware private algorithms</li>
	<li>Incentive mechanisms and game theory </li>
	<li>Privacy-preserving machine learning </li>
	<li>Privacy-preserving algorithms for medical applications </li>
	<li>Privacy-preserving algorithms for temporal data </li>
	<li>Privacy-preserving test cases and benchmarks</li>
	<li>Privacy and policy-making</li>
	<li>Secure multi-party computation</li>
	<li>Secret sharing techniques</li>
	<li>Trade-offs between privacy and utility </li>
	</ul>
	Position, perspective, and vision papers are also welcome. Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and datasets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples. 
	</section>


	<section id="submission" class="main">
	<h2><strong>Submission Information</strong></h2>
	<p>
	Submission URL: <a href="https://easychair.org/conferences/?conf=ppai20" 
	target="_blank">https://easychair.org/conferences/?conf=ppai20</a>
	<br>

	<h4>Submission Types</h4>
	<ul>
	<li><strong>Technical Papers</strong>: 
		Full-length research papers of up to 7 pages (excluding references and appendices) detailing high quality work in progress or work that could potentially be published at a major conference. 
	</li>
	<li><strong>Short Papers</strong>: 
	Position or short papers of up to 4 pages (excluding references and appendices) that describe initial work or the release of privacy-preserving benchmarks and datasets on the topics of interest. 
	</li>
	</ul>
	</p>

	<p>	
	All papers must be submitted in PDF format, using the AAAI-20 author kit. 
	Submissions should include the name(s), affiliations, and email addresses of all authors. 
	<br>
	Submissions will be refereed on the basis of technical quality, novelty, significance, and clarity. Each submission will be thoroughly reviewed by at least two program committee members.
	<br>
	Submissions of papers rejected from the AAAI 2020 technical program are welcomed. 
	Papers will be selected for oral and/or poster presentation at the workshop. 
	</p>

	<p>
	For questions about the submission process, contact the workshop <a href="#contact">co-chairs</a>.
	</p>
	</section>

	<section id="dates" class="main">
	<h2><strong>Important Dates</strong></h2>		
	<ul>
	<li>November 15, 2019 (AOE) - Submission Deadline </li>
    <li>December 4, 2019        - Acceptance Notification</li>
    <li>February 7, 2020 - Workshop Date (<strong>Full day</strong>)</li>
	</ul>
	</section>	
	
	<section id="papers" class="main">
	<h2><strong>Accepted Papers</strong></h2>		
	<h3>Accepted Oral Presentation</h3>
	<ul>
	<li><i>Gilie Gefen, Omer Ben-Porat, Moshe Tennenholtz and Elad Yom-Tov</i><br>
	<a href="papers/paper_8.pdf">Assessing the Value of Internet Data for Medical Applications</a></li>
	<li><i>Kai Wen Wang, Travis Dick and Maria-Florina Balcan</i><br>
	<a href="papers/paper_12.pdf">Scalable and provably accurate algorithms for differentially private distributed decision tree learning</a></li>
	<li><i>Reza Shokri, Martin Strobel and Yair Zick</i><br>
	<a href="papers/paper_17.pdf">Exploiting Transparency Measures for Membership Inference: a Cautionary Tale</a></li>
	
	<li><i>Shubhankar Mohapatra, Xi He, Gautam Kamath and Om Thakkar</i><br> Diffindo! Differentially Private Learning with Noisy Labels [Removed by authors' request]</li>

	<li><i>Chaitali Ashok Choudhary, Martine De Cock, Rafael Dowsley, Anderson Nascimento and Davis Railsback</i><br>
	<a href="papers/paper_24.pdf">Secure Training of Extra Trees Classifiers over Continuous Data</a></li>
	<li><i>Dominik Fay, Jens Sjölund and Tobias J. Oechtering</i><br>
	<a href="papers/paper_29.pdf">Private Learning for High-Dimensional Targets with PATE</a></li>
	</ul>

	<h3>Accepted Poster Presentations</h3>
	<ul>
	<li><i>Qiu Yuchen, Yuanyuan Qiao, Aimin Zhang and Jie Yang</i><br>
	<a href="papers/paper_1.pdf">Residence and Workplace Recovery: User Privacy Risk in Mobility Data</a></li>
	<li><i>Hanten Chang and Hiroyasu Ando</i><br>
	<a href="papers/paper_2.pdf">Privacy Preserving Data Sharing by Integrating Perturbed Distance Matrices</a></li>
	<li><i>Shreya Sharma, Xing Chaoping and Yang Liu</i><br>
	<a href="papers/paper_3.pdf">Privacy-Preserving Deep Learning with SPDZ</a></li>
	<li><i>Liyue Fan</i><br>
	<a href="papers/paper_9.pdf">A Survey of Differentially Private Generative Adversarial Networks</a></li>
	<li><i>Colin Wan, Zheng Li, Alicia Guo and Yue Zhao</i><br>
	<a href="papers/paper_10.pdf">SynC: A Unified Framework for Generating Synthetic Population with Gaussian Copula</a></li>
	<li><i>Ashish Dandekar, Debabrota Basu and Stephane Bressan</i><br>
	<a href="papers/paper_11.pdf">Differential Privacy at Risk: Bridging Randomness and Privacy Budget</a></li>
	<li><i>Ulrich Aïvodji, Sébastien Gambs and Timon Ther</i><br>
	<a href="papers/paper_13.pdf">GAMIN: An Adversarial Approach to Black-Box Model Inversion</a></li>
	<li><i>Longfei Zheng, Chaochao Chen, Yingting Liu, Bingzhe Wu, Xibin Wu, Li Wang, Lei Wang and Jun Zhou</i><br>
	<a href="papers/paper_15.pdf">Industrial Scale Privacy Preserving Deep Neural Network</a></li>
	<li><i>Yingting Liu, Chaochao Chen, Longfei Zheng, Li Wang and Jun Zhou</i><br>
	<a href="papers/paper_16.pdf">Privacy Preserving PCA for Multiparty Modeling</a></li>
	<li><i>Clémence Mauger, Gaël Le Mahec and Gilles Dequen</i><br>
	<a href="papers/paper_18.pdf">Modeling and Evaluation of k-anonymization Metrics</a></li>
	<li><i>Aleksei Triastcyn and Boi Faltings</i><br>
	<a href="papers/paper_19.pdf">Bayesian Differential Privacy for Machine Learning</a></li>
	<li><i>Himanshu Arora</i><br>
	<a href="papers/paper_20.pdf">Guided PATE for Scalable Learning</a></li>
	<li><i>Adam Richardson, Aris Filos-Ratsikas, Ljubomir Rokvic and Boi Faltings</i><br>
	<a href="papers/paper_25.pdf">Privately Computing Influence in Regression Models</a></li>
	<li><i>Hui Hu and Chao Lan</i><br>
	<a href="papers/paper_26.pdf">Inference Attack and Defense Mechanisms on the Distributed Private Fair Machine Learning Framework</a></li>
	<li><i>Yulin Zhang and Dylan Shell</i><br>
	<a href="papers/paper_27.pdf">Plans that Remain Private Even in Hindsight</a></li>
	<li><i>Junhong Cheng, Wenyan Liu, Xiaoling Wang, Xingjian Lu, Jing Feng and Yi Li</i><br>
	<a href="papers/paper_28.pdf">Adaptive Distributed Differential Privacy with SGD</a></li>
	</ul>
	</section>
	
	<section id="program" class="main">
	<h2><strong>Technical Program</strong></h2>
		  
	<strong>Location</strong>: Hilton New York Midtown, New York, NY, USA
	<br>
	Room: Clinton (on the second floor of the hotel).

	<ul>
		<li>8:45 - 9:00: <strong>Poster Setup and Opening Statement</strong></li>
		<li>9:00 - 9:45: <strong><a href="#invited1">Invited Talk</a>: Catuscia Palamidessi</strong></li>
		<li>9:45 - 10:30:
			<strong>Session I</strong><br>
			Session Chair: TBA
			<ul>
				<li>Gilie Gefen, Omer Ben-Porat, Moshe Tennenholtz and Elad Yom-Tov.<br>
				<a href="papers/paper_8.pdf">Assessing the Value of Internet Data for Medical Applications</a>.
				</li>
				<li>
				Reza Shokri, Martin Strobel and Yair Zick.<br>
				<a href="papers/paper_17.pdf">Exploiting Transparency Measures for Membership Inference: a Cautionary Tale</a>.
				</li>
				<li>
				Shubhankar Mohapatra, Xi He, Gautam Kamath and Om Thakkar.<br>
				<a href="#">Diffindo! Differentially Private Learning with Noisy Labels</a>.
				</li>
			</ul>
		</li>
		<li> 10:30 - 11:00: <strong>Break<sup>*</sup> and Poster Session</strong></li>
		<li> 11:00 - 11:45: <strong><a href="#invited2">Invited Talk</a>: Boi Faltings</strong></li>
		<li> 11:45 - 12:30: <strong>Poster Session</strong></li>
		<li> 12:30 - 13:50: <strong>Lunch</strong> (not sponsored)</li>
		<li> 13:50 - 14:45: <a href="#panel">Panel Discussion</a>
		<li>14:45 - 15:30: <strong><a href="#invited3">Invited Talk</a>: Aleksandar Nikolov</strong></li>
		<li> 15:30 - 16:00: <strong>Break<sup>*</sup> and Poster Session</strong> </li>
		<li> 16:00 - 16:45: <strong>Poster Session</strong> </li>
		<li> 16:45 - 17:30:
			<strong>Session II</strong><br>
			Session Chair: TBA
			<ul>
				<li>Kai Wen Wang, Travis Dick and Maria-Florina Balcan.<br>
				<a href="papers/paper_12.pdf">Scalable and provably accurate algorithms for differentially private distributed decision tree learning</a>.
				</li>
				<li>Chaitali Ashok Choudhary, Martine De Cock, Rafael Dowsley, Anderson Nascimento and Davis Railsback.<br>
				<a href="papers/paper_24.pdf">Secure Training of Extra Trees Classifiers over Continuous Data</a>.
				</li>
				<li>Dominik Fay, Jens Sjölund and Tobias J. Oechtering.<br>
				<a href="papers/paper_29.pdf">Private Learning for High-Dimensional Targets with PATE</a>.
				</li>
			</ul>
		</li>
		<li>17:30: End of Workshop</li>
	</ul>
	<p>
		<sup>*</sup>Coffee Breaks will be provided in the East Corridor Second Floor and the Concourse Floor.
	</p>

	<h3>Invited Speakers</h3>
	<td>
		<li id='invited2'>
			<a href="https://people.epfl.ch/boi.faltings?lang=en">Boi  Faltings</a>	(EPFL)
		<p class="tab">

		<strong>Privacy-Preserving Constraint Optimization</strong>
		<br>
		Artificial Intelligence can play an important role in modern society as a mediator between
		different parties, such as auctions and coordination mechanisms. However, the preferences and
		constraints involved in such mediation are private information and must be protected from leakage
		both to the mediator and to the other parties. I present different solutions to this problem
		based on homomorphic encryption and multiparty computation, and discuss open issues for further research.

		<br><br>
		<strong>Bio:&nbsp;</strong>

		Boi Faltings is a full professor of computer science at the Ecole Polytechnique Fédérale de Lausanne (EPFL),  where he heads the Artificial Intelligence Laboratory. He has held visiting positions at NEC Research Institute, Stanford University and the HongKong University of Science and Technology. He has co-founded 6 companies using AI for e-commerce and computer security and acted as advisor to several other companies. Prof. Faltings has published over 300 refereed papers and graduated over 35 Ph.D. students, several of which have won national and international awards. He is a fellow of the European Coordinating Committee for Artificial Intelligence and a fellow of the Association for Advancement of Artificial Intelligence (AAAI). He holds a Diploma from ETH Zurich and a Ph.D. from the University of Illinois at Urbana-Champaign.
		</p>
		</li>

		<li id="invited1"><a href="http://www.lix.polytechnique.fr/Labo/Catuscia.Palamidessi/">Catuscia	Palamidessi</a>	 (INRIA)
		
		<p class="tab">
		<strong>Machine learning and privacy: friends or enemies?</strong>
		<br>
		Recently a lot of research effort has been dedicated to show the risk for privacy connected to the use of machine learning. In this talk, I will explore the opposite perspective, and argue that machine learning can actually be useful for privacy. In particular, I will discuss<br>
		(1) How machine learning can help to estimate the leakage of private information in the black-box model, and <br>
		(2) How machine learning can help to construct mechanisms for privacy protection that approximate an optimal trade-off between privacy and utility.
		<br><br>
		<strong>Bio:&nbsp;</strong>
		Catuscia  Palamidessi is Director of Research at INRIA Saclay (since 2002), where she leads the team COMETE.
		She got her PhD from the University of Pisa in 1988.  She held Full Professor positions at the University of Genova, Italy (1994-1997) and at the Pennsylvania State University, USA (1998-2002). 
		Palamidessi's research interests include Privacy, Secure Information Flow,  and Concurrency. 
		Her past achievements include the proof of expressiveness gaps between various concurrent calculi, and
		the development  of a probabilistic version of the asynchronous  pi-calculus. 
		More recently, she has contributed to establish the foundations of probabilistic secure information flow, 
		she has proposed an extension of differential privacy, and geo-indistinguishability, an approach to location privacy. 
		In 2019 she has received an advanced ERC grant.
		</p>
		</li>

		<li id="invited3">
			<a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>  (University of Toronto)
		<p class="tab">
		<strong>The Power of Factorization Mechanisms for Answering Counting Queries</strong>
		<br>
		Many tasks in private data analysis can be reduced to answering a collection of counting queries, i.e. queries that ask what fraction of the dataset satisfies a given property. Counting queries, for example, capture contingency tables and CDFs, and can be used to implement learning algorithms in the Statistical Query model. A basic method to answer counting queries with differential privacy is to add IID Laplace or Gaussian noise to the query answers. Often, however, one can get much better error guarantees by instead answering a different set of “strategy queries” with IID noise, and then reconstructing answers to the original queries. Optimal strategy queries can be usually computed efficiently using convex optimization. The resulting factorization mechanisms give optimal error vs privacy trade-offs in various models of differential privacy and parameter regimes. In this talk, I will give a flavor of factorization mechanisms, and what we can prove about them. 

		<br><br>
		<strong>Bio:&nbsp;</strong>

		Aleksandar (Sasho) Nikolov is an assistant professor at the University of Toronto. Sasho received his PhD from Rutgers University, where his supervisor was S. Muthukrishnan, and did a postdoc with the Theory Group at Microsoft Research in Redmond. He is a Canada Research Chair in Algorithms and Privacy, and from 2012-14 was a Simons Graduate Fellow in Computer Science. Sasho is broadly interested in theoretical computer science and algorithms, and specifically in differential privacy, discrepancy theory, convex geometry and geometric algorithms.
		<p>
		</li>
	</td>
	<br>

	<h3 id='panel'>Panel Discussion</h3>
	
	<h4>Grand Challenges in Privacy in 2020: What are they and what are we missing?</h4>
	<strong>Panelists</strong>: 
		<ul>
			<li><a href="https://people.epfl.ch/boi.faltings?lang=en">Boi  Faltings</a>	(EPFL)</li>
			<li><a href="https://www.linkedin.com/in/apapadimitriou/">Antonis Papadimitriou</a> (Duality Technologies)</li>
			<li><a href="https://sebastiengambs.openum.ca">Sébastien Gambs</a> (Universite du Quebec a Montreal)</li>
			<li><a href="https://cset.georgetown.edu/about-us/">Helen Toner</a> (Georgetown's Center for Security and Emerging Technology)</li>
		</ul>
	</section>	
	<section id="committee" class="main">
	<h2><strong>Program Committee</strong></h2>
	<td>
		<li>Aws	Albarghouthi	-	University of Wisconsin-Madison	</li>
		<li>Carsten	Baum		-	Bar Ilan University	</li>
		<li>Aurélien	Bellet	-	INRIA	</li>
		<li>Elette	Boyle		-	Technion	</li>
		<li>Mark	Bun			- Boston University	</li>
		<li>Kamalika	Chaudhuri	-	University of California San Diego	</li>
		<li>Graham	Cormode		-	The University of Warwick	</li>
		<li>Marco	Gaboardi	-	Boston University	</li>
		<li>Antti	Honkela		- University of Helsinki	</li>
		<li>Dali    Kaafar         -   Data61-CSIRO</li>
		<li>Peter	Kairouz		-	Google AI	</li>
		<li>Kim	    Laine - Microsoft	</li>		
		<li>Audra	McMillan	-	Northeastern University	</li>
		<li>Sebastian	Meiser	-	University College London	</li>
		<li>Ilya	Mironov		- Google	</li>
		<li>Aleksandar	Nikolov	-	University of Toronto	</li>
		<li>Kobbi	Nissim		-	Georgetown University	</li>
		<li>Catuscia	Palamidessi	-	INRIA	</li>
		<li>Reza	Shokri		- National University of Singapore	</li>
		<li>Jonathan	Ullman	-	Northeastern University	</li>
		<li>Xiao	Wang		- Northwestern University	</li>
		<li>Zhiwei Steven Wu    -   University of Minnesota </li>
	</td>
	</section>

	<section id="contact" class="main">
	<h2><strong>Contact</h2></strong>

   	<strong>Workshop Chairs:</strong>
  	<ul>
    	<li><a href="http://nandofioretto.com" target="_blank">Ferdinando Fioretto</a> - Syracuse University</li>
    	<li><a href="http://pwp.gatech.edu/pascal-van-hentenryck/" target="_blank">Pascal Van Hentenryck</a> - Georgia Institute of Technology</li>
    	<li><a href="https://pwp.gatech.edu/rachel-cummings/" target="_blank">Rachel Cummings</a> - Georgia Institute of Technology</li>
  	</ul>

	<img src="images/email.png" alt=""  width="25"/>
	<a href="mailto:fioretto@gatech.edu?subject=PPAI-20 
			&pvh@isye.gatech.edu,rachelc@gatech.edu">contact us</a>

	</section>

	<!-- Footer -->
	<footer id="footer">

		<p class="copyright">&copy;Designed with <a href="https://html5up.net">HTML5 UP</a>.</p>
	</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/skel.min.js"></script>
	<script src="assets/js/util.js"></script>
	<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
	<script src="assets/js/main.js"></script>

	</body>
</html>
