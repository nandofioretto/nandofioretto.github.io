<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Ferdinando (Nando)  Fioretto</title>
    <meta name="author" content="Ferdinando (Nando)  Fioretto">
    <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar.">
    <meta name="keywords" content="Ferdinando Fioretto, AI, ML, Optimization, differential privacy, fairness, trustworthy, university of virginia">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Ferdinando (Nando) </span>Fioretto</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/awards/">awards</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/group/">group</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/bio/">bio</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/assets/cv/cvFioretto.pdf">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">

<h2 class="bibliography">2025</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ICLR</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:ICLR25" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning To Solve Differential Equation Constrained Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        Vincenzo Di Vito, Mostafa Mohammadian, Kyri Baker, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Learning Representations</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2410.01786" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Differential equations (DE) constrained optimization plays a critical role in numerous scientific and engineering fields, including energy systems, aerospace engineering, ecology, and finance, where optimal configurations or control strategies must be determined for systems governed by ordinary or stochastic differential equations. Despite its significance, the computational challenges associated with these problems have limited their practical use. To address these limitations, this paper introduces a learning-based approach to DE-constrained optimization that combines techniques from proxy optimization and neural differential equations. The proposed approach uses a dual-network architecture, with one approximating the control strategies, focusing on steady-state constraints, and another solving the associated DEs. This combination enables the approximation of optimal strategies while accounting for dynamic constraints in near real-time. Experiments across problems in energy optimization and finance modeling show that this method provides full compliance with dynamic constraints and it produces results up to 25 times more precise than other methods which do not explicitly model the system’s dynamic equations.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:ICLR25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning To Solve Differential Equation Constrained Optimization Problems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vito, Vincenzo Di and Mohammadian, Mostafa and Baker, Kyri and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2410.01786}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NAACL</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:NAACL" class="col-sm-8">
        <!-- Title -->
        <div class="title">Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion</div>
        <!-- Author -->
        <div class="author">
        

        Jacob K Christopher, Michael Cardei, Brian R Bartoldson, Bhavya Kailkhura, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em></em> 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="">Efficient Natural Language and Speech Processing workshop (NeurIPS 2024)</a></abbr>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2408.05636" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Speculative decoding has emerged as a widely adopted method to accelerate large language model inference without sacrificing the quality of the model outputs. While this technique has facilitated notable speed improvements by enabling parallel sequence verification, its efficiency remains inherently limited by the reliance on incremental token generation in existing draft models. To overcome this limitation, this paper proposes an adaptation of speculative decoding which uses discrete diffusion models to generate draft sequences. This allows parallelization of both the drafting and verification steps, providing significant speed-ups to the inference process. Our proposed approach, Speculative Diffusion Decoding (SpecDiff), is validated on standard language generation benchmarks and empirically demonstrated to provide a up to 8.7x speed-up over standard generation processes and up to 2.5x speed-up over existing speculative decoding approaches.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:NAACL</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Christopher, Jacob K and Cardei, Michael and Bartoldson, Brian R and Kailkhura, Bhavya and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2408.05636}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AISTATS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:AISTATS25" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially Private Data Release on Graphs: Inefficiencies and Unfairness</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Diptangshu Sen, and Juba Ziani</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference for Artificial Intelligence and Statistics</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2408.05246" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Networks are crucial components of many sectors, including telecommunications, healthcare, finance, energy, and transportation.The information carried in such networks often contains sensitive user data, like location data for commuters and packet data for online users. Therefore, when considering data release for networks, one must ensure that data release mechanisms do not leak information about individuals, quantified in a precise mathematical sense. Differential Privacy (DP) is the widely accepted, formal, state-of-the-art technique, which has found use in a variety of real-life settings including the 2020 U.S. Census, Apple users’ device data, or Google’s location data. Yet, the use of DP comes with new challenges, as the noise added for privacy introduces inaccuracies or biases and further, DP techniques can also distribute these biases disproportionately across different populations, inducing fairness issues. The goal of this paper is to characterize the impact of DP on bias and unfairness in the context of releasing information about networks, taking a departure from previous work which has studied these effects in the context of private population counts release (such as in the U.S. Census). To this end, we consider a network release problem where the network structure is known to all, but the weights on edges must be released privately. We consider the impact of this private release on a simple downstream decision-making task run by a third-party, which is to find the shortest path between any two pairs of nodes and recommend the best route to users. This setting is of highly practical relevance, mirroring scenarios in transportation networks, where preserving privacy while providing accurate routing information is crucial. Our work provides theoretical foundations and empirical evidence into the bias and unfairness arising due to privacy in these networked decision problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:AISTATS25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially Private Data Release on Graphs: Inefficiencies and Unfairness}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Sen, Diptangshu and Ziani, Juba}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference for Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2408.05246}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:AAAI25" class="col-sm-8">
        <!-- Title -->
        <div class="title">Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes</div>
        <!-- Author -->
        <div class="author">
        

        Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2408.08471" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Statistical agencies rely on sampling techniques to collect socio-demographic data crucial for policy-making and resource allocation. This paper shows that surveys of important societal relevance introduce sampling errors that unevenly impact group-level estimates, thereby compromising fairness in downstream decisions. To address these issues, this paper introduces an optimization approach modeled on real-world survey design processes, ensuring sampling costs are optimized while maintaining error margins within prescribed tolerances. Additionally, privacy-preserving methods used to determine sampling rates can further impact these fairness issues. The paper explores the impact of differential privacy on the statistics informing the sampling process, revealing a surprising effect: not only the expected negative effect from the addition of noise for differential privacy is negligible, but also this privacy noise can in fact reduce unfairness as it positively biases smaller counts. These findings are validated over an extensive analysis using datasets commonly applied in census statistics.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:AAAI25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fairness Issues and Mitigations in (Differentially Private) Socio-demographic Data Processes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ko, Joonhyuk and Ziani, Juba and Das, Saswat and Williams, Matt and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2408.08471}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">SatML</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TFKTP:SatML25" class="col-sm-8">
        <!-- Title -->
        <div class="title">FairDP: Certified Fairness with Differential Privacy</div>
        <!-- Author -->
        <div class="author">
        

        Khang Tran, <em>Ferdinando Fioretto</em>, Issa Khalil, My T. Thai, and NhatHai Phan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE Secure and Trustworthy Machine Learning Conference (SaTML 2025)</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2305.16474" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces FairDP, a novel mechanism designed to simultaneously ensure differential privacy (DP) and fairness. FairDP operates by independently training models for distinct individual groups, using group-specific clipping terms to assess and bound the disparate impacts of DP. Throughout the training process, the mechanism progressively integrates knowledge from group models to formulate a comprehensive model that balances privacy, utility, and fairness in downstream tasks. Extensive theoretical and empirical analyses validate the efficacy of FairDP, demonstrating improved trade-offs between model utility, privacy, and fairness compared with existing methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TFKTP:SatML25</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Khang and Fioretto, Ferdinando and Khalil, Issa and Thai, My T. and Phan, NhatHai}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FairDP: Certified Fairness with Differential Privacy}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Secure and Trustworthy Machine Learning Conference (SaTML 2025)}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2305.16474}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#99ccff"><a href="">CoLoRAI</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best paepr award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:colorai25" class="col-sm-8">
        <!-- Title -->
        <div class="title">Low-rank finetuning for LLMs: A fairness perspective</div>
        <!-- Author -->
        <div class="author">
        

        Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI CoLoRAI Workshop</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best paepr award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2405.18572" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Low-rank approximation techniques have become the de facto standard for fine-tuning Large Language Models (LLMs) due to their reduced computational and memory requirements. This paper investigates the effectiveness of these methods in capturing the shift of fine-tuning datasets from the initial pre-trained data distribution. Our findings reveal that there are cases in which low-rank fine-tuning falls short in learning such shifts. This, in turn, produces non-negligible side effects, especially when fine-tuning is adopted for toxicity mitigation in pre-trained models, or in scenarios where it is important to provide fair models. Through comprehensive empirical evidence on several models, datasets, and tasks, we show that low-rank fine-tuning inadvertently preserves undesirable biases and toxic behaviors. We also show that this extends to sequential decision-making tasks, emphasizing the need for careful evaluation to promote responsible LLMs development.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:colorai25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Low-rank finetuning for LLMs: A fairness perspective}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Das, Saswat and Romanelli, Marco and Tran, Cuong and Reza, Zarreen and Kailkhura, Bhavya and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2405.18572}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI CoLoRAI Workshop}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2405.18572}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#99ccff"><a href="">MAPF</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:MAPF25" class="col-sm-8">
        <!-- Title -->
        <div class="title">Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Jinhao Liang, Jacob Christopher, Sven Koenig, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In The 6th International Workshop on Multi-Agent Path Finding, at AAAI</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="">Combining AI and OR/MS for Better Trustworthy Decision Making (AAAI 2025)</a></abbr>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2412.17993" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics, requiring the computation of collision-free paths for multiple agents moving from their respective start to goal positions. The complexity of coordinating multiple agents in a shared environment poses significant challenges, especially in continuous spaces where traditional optimization algorithms fall short with scalability. Recently, diffusion models have been successfully applied to single-agent contexts, offering advantages such as modeling complex trajectory distributions and generating smooth paths that navigate high-dimensional spaces effectively. However, such models have struggled to ensure constraints feasibility, such as non-collision. Additionally, extending diffusion models to MAPF brings an additional level of complexity due to the necessity to satisfy inter-agent constraints. In this work, we propose a novel combination of constrained optimization with diffusion models for MAPF in continuous spaces. Such a unique combination enables the direct generation of feasible multi-agent trajectories, considering collision avoidance and kinematic feasibility. Additionally, the paper proposes an augmented Lagrangian method that reduces complexity and enhances practicality for real-time applications. The effectiveness of our approach is demonstrated across various simulated scenarios.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:MAPF25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liang, Jinhao and Christopher, Jacob and Koenig, Sven and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{39}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 6th International Workshop on Multi-Agent Path Finding, at AAAI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#99ccff"><a href="">AIORMS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:AIAIbridge25b" class="col-sm-8">
        <!-- Title -->
        <div class="title">OPF-Net: Real-Time Stability Constrained AC Optimal Power Flow</div>
        <!-- Author -->
        <div class="author">
        

        Vincenzo Di Vito, Mostafa Mohammadian, Kyri Baker, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI 2025 Bridge on Explainable AI, Energy and Critical Infrastructure Systems</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/https://arxiv.org/abs/2410.19157" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent developments in applying machine learning to address Alternating Current Optimal Power Flow (AC OPF) problems have demonstrated significant potential in providing close to optimal solutions for generator dispatch in near real-time. While these learning to optimize methods have demonstrated remarkable performance on steady-state operations, practical applications often demand compliance with dynamic constraints when used for fast-timescale optimization. This paper addresses this gap and develops a real-time stability-constrained OPF model (DynOPF-Net) that simultaneously addresses both optimality and dynamical stability within learning-assisted grid operations. The model is a unique integration of learning to optimize that learns a mapping from load conditions to OPF solutions, capturing the OPF’s physical and engineering constraints, with Neural Ordinary Differential Equations, capturing generator dynamics, enabling the inclusion of a subset of stability constraints. Numerical results on the WSCC 9-bus and IEEE 57-bus benchmark systems demonstrate that DynOPF-Net can produce highly accurate AC-OPF solutions while also ensuring system stability, contrasting the unstable results obtained by state-of-the-art LtO methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:AIAIbridge25b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{OPF-Net: Real-Time Stability Constrained AC Optimal Power Flow}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vito, Vincenzo Di and Mohammadian, Mostafa and Baker, Kyri and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI 2025 Bridge on Explainable AI, Energy and Critical Infrastructure Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:25d" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained Language Generation with Discrete Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Michael Cardei, Jacob K Christopher, Thomas Hartvigsen, Brian R. Bartoldson, Bhavya Kailkhura, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2503.09790" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Constraints are critical in text generation as LLM outputs are often unreliable when it comes to ensuring generated outputs adhere to user defined instruction or general safety guidelines. To address this gap, we present Constrained Discrete Diffusion (CDD), a novel method for enforcing constraints on natural language by integrating discrete diffusion models with differentiable optimization. Unlike conventional text generators, which often rely on post-hoc filtering or model retraining for controllable generation, we propose imposing constraints directly into the discrete diffusion sampling process. We illustrate how this technique can be applied to satisfy a variety of natural language constraints, including (i) toxicity mitigation by preventing harmful content from emerging, (ii) character and sequence level lexical constraints, and (iii) novel molecule sequence generation with specific property adherence. Experimental results show that our constraint-aware procedure achieves high fidelity in meeting these requirements while preserving fluency and semantic coherence, outperforming auto-regressive and existing discrete diffusion approaches.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:25d</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained Language Generation with Discrete Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cardei, Michael and Christopher, Jacob K and Hartvigsen, Thomas and Bartoldson, Brian R. and Kailkhura, Bhavya and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2503.09790}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2503.09790}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:25c" class="col-sm-8">
        <!-- Title -->
        <div class="title">Training-Free Constrained Generation With Stable Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Stefano Zampini, Jacob K Christopher, Luca Oneto, Davide Anguita, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2502.05625" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly. However, their current utility in these fields is severely limited by an inability to enforce strict adherence to physical laws and domain-specific constraints. Without this grounding, the deployment of such models in critical applications, ranging from material science to safety-critical systems, remains impractical. This paper addresses this fundamental limitation by proposing a novel approach to integrate stable diffusion models with constrained optimization frameworks, enabling them to generate outputs that satisfy stringent physical and functional requirements. We demonstrate the effectiveness of this approach through material science experiments requiring adherence to precise morphometric properties, inverse design problems involving the generation of stress-strain responses using video generation with a simulator in the loop, and safety settings where outputs must avoid copyright infringement.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:25c</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Training-Free Constrained Generation With Stable Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zampini, Stefano and Christopher, Jacob K and Oneto, Luca and Anguita, Davide and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2502.05625}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2502.05625}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:25b" class="col-sm-8">
        <!-- Title -->
        <div class="title">Gen-DFL: Decision-Focused Generative Learning for Robust Decision Making</div>
        <!-- Author -->
        <div class="author">
        

        Prince Zizhuang Wang, Jinhao Liang, Shuyi Chen, <em>Ferdinando Fioretto</em>, and Shixiang Zhu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2502.05468" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Decision-focused learning (DFL) integrates predictive models with downstream optimization, directly training machine learning models to minimize decision errors. While DFL has been shown to provide substantial advantages when compared to a counterpart that treats the predictive and prescriptive models separately, it has also been shown to struggle in high-dimensional and risk-sensitive settings, limiting its applicability in real-world settings. To address this limitation, this paper introduces decision-focused generative learning (Gen-DFL), a novel framework that leverages generative models to adaptively model uncertainty and improve decision quality. Instead of relying on fixed uncertainty sets, Gen-DFL learns a structured representation of the optimization parameters and samples from the tail regions of the learned distribution to enhance robustness against worst-case scenarios. This approach mitigates over-conservatism while capturing complex dependencies in the parameter space. The paper shows, theoretically, that Gen-DFL achieves improved worst-case performance bounds compared to traditional DFL. Empirically, it evaluates Gen-DFL on various scheduling and logistics problems, demonstrating its strong performance against existing DFL methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:25b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gen-DFL: Decision-Focused Generative Learning for Robust Decision Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Prince Zizhuang and Liang, Jinhao and Chen, Shuyi and Fioretto, Ferdinando and Zhu, Shixiang}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2502.05468}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2502.05468}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:25a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Jinhao Liang, Jacob K Christopher, Sven Koenig, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2025
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2502.03607" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address this challenge, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:25a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liang, Jinhao and Christopher, Jacob K and Koenig, Sven and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2502.03607}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2502.03607}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2024</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.jair.org/index.php/jair" rel="external nofollow noopener" target="_blank">JAIR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:jair24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities</div>
        <!-- Author -->
        <div class="author">
        

        Jayanta Mandi, James Kotary, Senne Berden, Maxime Mulamba, Victor Bucarey, Tias Guns, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2307.13565" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system. This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock. This paper presents a comprehensive review of DFL. It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models, introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL. Finally, the study provides valuable insights into current and potential future avenues in DFL research.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:jair24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mandi, Jayanta and Kotary, James and Berden, Senne and Mulamba, Maxime and Bucarey, Victor and Guns, Tias and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{81}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1623--1701}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2307.13565}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:NeurIPS24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained Synthesis with Projected Diffusion Models</div>
        <!-- Author -->
        <div class="author">
        

        Jacob K Christopher, Stephen Baek, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="https://ml4physicalsciences.github.io/2024/" rel="external nofollow noopener" target="_blank">Machine Learning and the Physical Sciences Workshop (NeurIPS 2024)</a></abbr>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="TBA" class="btn btn-sm z-depth-0" role="button">Online</a>
            <a href="http://arxiv.org/abs/2402.03559" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Generative diffusion models excel at robustly synthesizing coherent content from raw noise through a sequential process. However, their direct application in scenarios requiring outputs to adhere to specific, stringent criteria faces several severe challenges. This paper aims at overcome these challenges and introduces Projected Generative Diffusion Models (PGDM), an approach that recast traditional diffusion models sampling into a constrained-optimization problem. This enables the application of an iterative projections method to ensure that generated data faithfully adheres to specified constraints or physical principles. This paper provides theoretical support for the ability of PGDM to synthesize outputs from a feasible subdistribution under a restricted class of constraints while also providing large empirical evidence in the case of complex non-convex constraints and ordinary differential equations. These capabilities are demonstrated by physics-informed motion in video generation, trajectory optimization in path planning, and morphometric properties adherence in material science.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:NeurIPS24</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained Synthesis with Projected Diffusion Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Christopher, Jacob K and Baek, Stephen and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{TBA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:NeurIPS24b" class="col-sm-8">
        <!-- Title -->
        <div class="title">Physics-Aware Generative Diffusion Models for Micro-structure Material Design</div>
        <!-- Author -->
        <div class="author">
        

        Jacob K Christopher, Stephen Baek, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>AI 4 Material Science workshop, at NeurIPS</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="TBA" class="btn btn-sm z-depth-0" role="button">Online</a>
            <a href="http://arxiv.org/abs/2402.03559" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Generative diffusion models excel at robustly synthesizing coherent content from raw noise through a sequential process. However, their direct application in scenarios requiring outputs to adhere to specific, stringent criteria faces several severe challenges. This paper aims at overcome these challenges and introduces Projected Generative Diffusion Models (PGDM), an approach that recast traditional diffusion models sampling into a constrained-optimization problem. This enables the application of an iterative projections method to ensure that generated data faithfully adheres to specified constraints or physical principles. This paper provides theoretical support for the ability of PGDM to synthesize outputs from a feasible subdistribution under a restricted class of constraints while also providing large empirical evidence in the case of complex non-convex constraints and ordinary differential equations. These capabilities are demonstrated by physics-informed motion in video generation, trajectory optimization in path planning, and morphometric properties adherence in material science.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:NeurIPS24b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Physics-Aware Generative Diffusion Models for Micro-structure Material Design}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Christopher, Jacob K and Baek, Stephen and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{AI 4 Material Science workshop, at NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{TBA}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:neurIPS_w24a" class="col-sm-8">
        <!-- Title -->
        <div class="title">The Data Minimization Principle in Machine Learning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Prakhar Ganesh, Cuong Tran, and Reza Shokri</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In NeurIPS 2024 Workshop on Regulatory ML</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="">Workshop on Generative AI and Law (ICML 2024)</a></abbr>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Oral</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The principle of data minimization requires organizations to \emphcollect, process, and retain only personal data that is adequate, relevant, and limited to what is necessary for specified objectives. It’s grounded in the expectation that not  all collected data is essential for the objective and, instead, contributes to a heightened risk of information leakage.
  However, despite its legal significance and endorsement by global data protection regulations,
  the data minimization principle lacks a mathematical formalization suitable for real-world ML applications. In particular, the current discourse on data minimization practices often overlooks two crucial aspects: \bf (1) the individualized nature of minimization (e.g., information that is unimportant for an individual may be critical for another) and \bf (2) its intrinsic link to data privacy.

  To overcome these limitations, this paper introduces a formal framework for data minimization in ML while being faithful to its legal notion; adapts and evaluates various optimization algorithms to solve the problem of data minimization; and analyzes their compatibility with real-world privacy.
  In particular, we seek to answer a critical question: “Do data minimization requirements in various regulations meet privacy expectations in legal frameworks?” Our evaluations reveal that the answer is, unfortunately, no. While being an implicit intention, the requirements of data minimization are not necessarily aligned with risk of reconstruction and re-identification and thus may not provide the expected privacy protection.

  With this work, we aim to lay down a path for future research for developing ML systems that comply with the legal requirements of data minimization.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:neurIPS_w24a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Data Minimization Principle in Machine Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Ganesh, Prakhar and Tran, Cuong and Shokri, Reza}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS 2024 Workshop on Regulatory ML}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CDC</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:CCD24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Metric Learning to Accelerate Convergence of Operator Splitting Methods for Differentiable Parametric Programming</div>
        <!-- Author -->
        <div class="author">
        

        Ethan King, James Kotary, <em>Ferdinando Fioretto</em>, and Jan Drgona</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE Conference on Decision and Control (CDC)</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2404.00882" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent work has shown a variety of ways in which machine learning can be used to accelerate the solution of constrained optimization problems. Increasing demand for real-time decision-making capabilities in applications such as artificial intelligence and optimal control has led to a variety of approaches, based on distinct strategies. This work proposes a novel approach to learning optimization, in which the underlying metric space of a proximal operator splitting algorithm is learned so as to maximize its convergence rate. While prior works in optimization theory have derived optimal metrics for limited classes of problems, the results do not extend to many practical problem forms including general Quadratic Programming (QP). This paper shows how differentiable optimization can enable the end-to-end learning of proximal metrics, enhancing the convergence of proximal algorithms for QP problems beyond what is possible based on known theory. Additionally, the results illustrate a strong connection between the learned proximal metrics and active constraints at the optima, leading to an interpretation in which the learning of proximal metrics can be viewed as a form of active set learning.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:CCD24</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Metric Learning to Accelerate Convergence of Operator Splitting Methods for Differentiable Parametric Programming}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{King, Ethan and Kotary, James and Fioretto, Ferdinando and Drgona, Jan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Decision and Control (CDC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2404.00882}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ECAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:ecai24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and Optimization</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, Vincenzo Di Vito, Jacob Christopher, Pascal Van Hentenryck, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Artificial Intelligence</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2311.13087" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Predict-Then-Optimize framework uses machine learning models to predict unknown parameters of an optimization problem from features before solving. While this traditional setting is common to many real-world decision processes, recently it has been shown that decision quality can be substantially improved by solving and differentiating the optimization problem in the training loop. However, this approach requires solving optimization in the loop along with handcrafted, problem-specific rules for backpropagation through the optimization step, challenging its applicability to a broad class of optimization problems. This paper proposes an alternative method, in which optimal solutions are learned directly from the observable features by joint predictive models. The approach is generic, and based on an adaptation of the Learning-to-Optimize paradigm, from which a rich variety of existing techniques can be employed. Experimental evaluations show the ability of several Learning-to-Optimize methods to provide efficient and accurate solutions to an array of challenging Predict-Then-Optimize problems</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:ecai24</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Vito, Vincenzo Di and Christopher, Jacob and Hentenryck, Pascal Van and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2311.13087}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ICML</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:icml24a" class="col-sm-8">
        <!-- Title -->
        <div class="title">On The Fairness Impacts of Hardware Selection in Machine Learning</div>
        <!-- Author -->
        <div class="author">
        

        Sree Harsha Nelaturu, Nishaanth Kanna Ravichandran, Cuong Tran, Sara Hooker, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2312.03886" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the machine learning ecosystem, hardware selection is often regarded as a mere utility, overshadowed by the spotlight on algorithms and data. This oversight is particularly problematic in contexts like ML-as-a-service platforms, where users often lack control over the hardware used for model deployment. How does the choice of hardware impact generalization properties? This paper investigates the influence of hardware on the delicate balance between model performance and fairness. We demonstrate that hardware choices can exacerbate existing disparities, attributing these discrepancies to variations in gradient flows and loss surfaces across different demographic groups. Through both theoretical and empirical analysis, the paper not only identifies the underlying factors but also proposes an effective strategy for mitigating hardware-induced performance imbalances.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:icml24a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On The Fairness Impacts of Hardware Selection in Machine Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nelaturu, Sree Harsha and Ravichandran, Nishaanth Kanna and Tran, Cuong and Hooker, Sara and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2312.03886}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ICML</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:icml24b" class="col-sm-8">
        <!-- Title -->
        <div class="title">Disparate Impact on Group Accuracy of Linearization for Private Inference</div>
        <!-- Author -->
        <div class="author">
        

        Saswat Das, Marco Romanelli, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Machine Learning</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2402.03629" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Ensuring privacy-preserving inference on cryptographically secure data is a well-known computational challenge. To alleviate the bottleneck of costly cryptographic computations in non-linear activations, recent methods have suggested linearizing a targeted portion of these activations in neural networks. This technique results in significantly reduced runtimes with often negligible impacts on accuracy. In this paper, we demonstrate that such computational benefits may lead to increased fairness costs. Specifically, we find that reducing the number of ReLU activations disproportionately decreases the accuracy for minority groups compared to majority groups. To explain these observations, we provide a mathematical interpretation under restricted assumptions about the nature of the decision boundary, while also showing the prevalence of this problem across widely used datasets and architectures. Finally, we show how a simple procedure altering the fine-tuning step for linearized models can serve as an effective mitigation strategy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:icml24b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Disparate Impact on Group Accuracy of Linearization for Private Inference}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Das, Saswat and Romanelli, Marco and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2402.03629}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ICML</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:icml_w24b" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentiable Approximations of Fair OWA Optimization</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, James Kotary, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ICML 2024 Workshop on Differentiable Almost Everything</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Decision processes in AI and operations research often involve parametric optimization problems, whose unknown parameters must be inferred from data. The Predict-Then-Optimize (PtO) paradigm maximizes decision quality by training parametric prediction models end-to-end with subsequent constrained optimization. This paper extends PtO to handle the optimization of nondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their ability to ensure fair and robust solutions with respect to multiple objectives. By proposing efficient differentiable approximations of OWA optimization, it provides a framework for integrating fair optimization concepts with parametric prediction under uncertainty.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:icml_w24b</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentiable Approximations of Fair OWA Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Kotary, James and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICML 2024 Workshop on Differentiable Almost Everything}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=NBt4ZBOFth}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">UAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:uai24" class="col-sm-8">
        <!-- Title -->
        <div class="title">End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, James Kotary, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Conference on Uncertainty in Artificial Intelligence</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2402.07772" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many decision processes in artificial intelligence and operations research are modeled by parametric optimization problems whose defining parameters are unknown and must be inferred from observable data. The Predict-Then-Optimize (PtO) paradigm in machine learning aims to maximize downstream decision quality by training the parametric inference model end-to-end with the subsequent constrained optimization. This requires backpropagation through the optimization problem using approximation techniques specific to the problem’s form, especially for nondifferentiable linear and mixed-integer programs. This paper extends the PtO methodology to optimization problems with nondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their ability to ensure properties of fairness and robustness in decision models. Through a collection of training techniques and proposed application settings, it shows how optimization of OWA functions can be effectively integrated with parametric prediction for fair and robust optimization under uncertainty.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:uai24</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Kotary, James and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Uncertainty in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2402.07772}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:ijcai24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Fairness Increases Adversarial Vulnerability</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, Keyu Zhu, Pascal Van Hentenryck, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.48550/arXiv.2211.11835" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2211.11835" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The remarkable performance of deep learning models and their applications in consequential domains (e.g., facial recognition) introduces important challenges at the intersection of equity and security. Fairness and robustness are two desired notions often required in learning models. Fairness ensures that models do not disproportionately harm (or benefit) some groups over others, while robustness measures the models’ resilience against small input perturbations.
  This paper shows the existence of a dichotomy between fairness and robustness, and analyzes when achieving fairness decreases the model robustness to adversarial samples. The reported analysis sheds light on the factors causing such contrasting behavior, suggesting that distance to the decision boundary across groups as a key explainer for this behavior. Extensive experiments on non-linear models and different architectures validate the theoretical findings in multiple vision domains. Finally, the paper proposes a simple, yet effective, solution to construct models achieving good tradeoffs between fairness and robustness.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:ijcai24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Zhu, Keyu and Hentenryck, Pascal Van and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fairness Increases Adversarial Vulnerability}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{TBA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/arXiv.2211.11835}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2211.11835}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:aaai24" class="col-sm-8">
        <!-- Title -->
        <div class="title">Finding epsilon and delta of Traditional Disclosure Control Systems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Keyu Zhu, Pascal Van Hentenryck, Saswat Das, and Christine Task</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/30204" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2301.12204" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper analyzes the privacy of traditional Statistical Disclosure Control (SDC) systems under a differential privacy interpretation. SDCs, such as cell suppression and swapping promise to safeguard the confidentiality of data and are routinely adopted in data analyses with profound societal and economic impacts. Through a formal analysis and empirical evaluation on US Census data, the paper shows that widely adopted SDC systems not only induce vastly larger privacy losses than classical differential privacy mechanisms, but, they may also come at a cost of larger accuracy and fairness.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:aaai24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Zhu, Keyu and Hentenryck, Pascal Van and Das, Saswat and Task, Christine}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Finding epsilon and delta of Traditional Disclosure Control Systems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{38}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{22013--22020}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/30204}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">FAccT</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:facct24a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, James Kotary, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="doi.acm.org?doi=3630106.3661932" class="btn btn-sm z-depth-0" role="button">Online</a>
            <a href="http://arxiv.org/abs/2402.05252" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constrained optimizations of OWA objectives, enabling their use in integrated prediction and decision models.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Fioretto:facct24a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Kotary, James and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2508--2517}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{doi.acm.org?doi=3630106.3661932}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24l" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy Overview and Fundamental Techniques</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, and Juba Ziani</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2411.04710" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This chapter is meant to be part of the book "Differential Privacy in Artificial Intelligence: From Theory to Practice" and provides an introduction to Differential Privacy. It starts by illustrating various attempts to protect data privacy, emphasizing where and why they failed, and providing the key desiderata of a robust privacy definition. It then defines the key actors, tasks, and scopes that make up the domain of privacy-preserving data analysis. Following that, it formalizes the definition of Differential Privacy and its inherent properties, including composition, post-processing immunity, and group privacy. The chapter also reviews the basic techniques and mechanisms commonly used to implement Differential Privacy in its pure and approximate forms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24l</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy Overview and Fundamental Techniques}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van and Ziani, Juba}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2411.04710}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2411.04710}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24k" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning to Optimize meets Neural-ODE: Real-Time, Stability-Constrained AC OPF</div>
        <!-- Author -->
        <div class="author">
        

        Vincenzo Di Vito, Mostafa Mohammadian, Kyri Baker, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2410.19157" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent developments in applying machine learning to address Alternating Current Optimal Power Flow (AC OPF) problems have demonstrated significant potential in providing close to optimal solutions for generator dispatch in near real-time. While these learning to optimize methods have demonstrated remarkable performance on steady-state operations, practical applications often demand compliance with dynamic constraints when used for fast-timescale optimization. This paper addresses this gap and develops a real-time stability-constrained OPF model (DynOPF-Net) that simultaneously addresses both optimality and dynamical stability within learning-assisted grid operations. The model is a unique integration of learning to optimize that learns a mapping from load conditions to OPF solutions, capturing the OPF’s physical and engineering constraints, with Neural Ordinary Differential Equations, capturing generator dynamics, enabling the inclusion of a subset of stability constraints. Numerical results on the WSCC 9-bus and IEEE 57-bus benchmark systems demonstrate that DynOPF-Net can produce highly accurate AC-OPF solutions while also ensuring system stability, contrasting the unstable results obtained by state-of-the-art LtO methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24k</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Optimize meets Neural-ODE: Real-Time, Stability-Constrained AC OPF}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vito, Vincenzo Di and Mohammadian, Mostafa and Baker, Kyri and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2410.19157}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2410.19157}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24j" class="col-sm-8">
        <!-- Title -->
        <div class="title">End-to-End Optimization and Learning of Fair Court Schedules</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, James Kotary, Lauryn P. Gouldin, William Yeoh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2410.17415" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Criminal courts across the United States handle millions of cases every year, and the scheduling of those cases must accommodate a diverse set of constraints, including the preferences and availability of courts, prosecutors, and defense teams. When criminal court schedules are formed, defendants’ scheduling preferences often take the least priority, although defendants may face significant consequences (including arrest or detention) for missed court dates. Additionally, studies indicate that defendants’ nonappearances impose costs on the courts and other system stakeholders. To address these issues, courts and commentators have begun to recognize that pretrial outcomes for defendants and for the system would be improved with greater attention to court processes, including \emphcourt scheduling practices. There is thus a need for fair criminal court pretrial scheduling systems that account for defendants’ preferences and availability, but the collection of such data poses logistical challenges. Furthermore, optimizing schedules fairly across various parties’ preferences is a complex optimization problem, even when such data is available. In an effort to construct such a fair scheduling system under data uncertainty, this paper proposes a joint optimization and learning framework that combines machine learning models trained end-to-end with efficient matching algorithms. This framework aims to produce court scheduling schedules that optimize a principled measure of fairness, balancing the availability and preferences of all parties.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24j</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Optimization and Learning of Fair Court Schedules}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Kotary, James and Gouldin, Lauryn P. and Yeoh, William and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2410.17415}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2410.17415}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24e" class="col-sm-8">
        <!-- Title -->
        <div class="title">The Data Minimization Principle in Machine Learning</div>
        <!-- Author -->
        <div class="author">
        

        Prakhar Ganesh, Cuong Tran, Reza Shokri, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2405.19471" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The principle of data minimization aims to reduce the amount of data collected, processed or retained to minimize the potential for misuse, unauthorized access, or data breaches. Rooted in privacy-by-design principles, data minimization has been endorsed by various global data protection regulations. However, its practical implementation remains a challenge due to the lack of a rigorous formulation. This paper addresses this gap and introduces an optimization framework for data minimization based on its legal definitions. It then adapts several optimization algorithms to perform data minimization and conducts a comprehensive evaluation in terms of their compliance with minimization objectives as well as their impact on user privacy. Our analysis underscores the mismatch between the privacy expectations of data minimization and the actual privacy benefits, emphasizing the need for approaches that account for multiple facets of real-world privacy risks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24e</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Data Minimization Principle in Machine Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ganesh, Prakhar and Tran, Cuong and Shokri, Reza and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2405.19471}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2405.19471}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24c" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Constrained Optimization with Deep Augmented Lagrangian Methods</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2403.03454" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning to Optimize (LtO) is a problem setting in which a machine learning (ML) model is trained to emulate a constrained optimization solver. Learning to produce optimal and feasible solutions subject to complex constraints is a difficult task, but is often made possible by restricting the input space to a limited distribution of related problems. Most LtO methods focus on directly learning solutions to the primal problem, and applying correction schemes or loss function penalties to encourage feasibility. This paper proposes an alternative approach, in which the ML model is trained instead to predict dual solution estimates directly, from which primal estimates are constructed to form dual-feasible solution pairs. This enables an end-to-end training scheme is which the dual objective is maximized as a loss function, and solution estimates iterate toward primal feasibility, emulating a Dual Ascent method. First it is shown that the poor convergence properties of classical Dual Ascent are reflected in poor convergence of the proposed training scheme. Then, by incorporating techniques from practical Augmented Lagrangian methods, we show how the training scheme can be improved to learn highly accurate constrained optimization solvers, for both convex and nonconvex problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24c</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Constrained Optimization with Deep Augmented Lagrangian Methods}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2403.03454}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2403.03454}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="Fioretto:24a" class="col-sm-8">
        <!-- Title -->
        <div class="title">Analyzing and Enhancing the Backward-Pass Convergence of Unrolled Optimization</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, Jacob Christopher, My H Dinh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2024
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2312.17394" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which often lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the entire chain of operations executed by an iterative optimization solver. This paper provides theoretical insights into the backward pass of unrolled optimization, showing that it is asymptotically equivalent to the solution of a linear system by a particular iterative method. Several practical pitfalls of unrolling are demonstrated in light of these insights, and a system called Folded Optimization is proposed to construct more efficient backpropagation rules from unrolled solver implementations. Experiments over various end-to-end optimization and learning tasks demonstrate the advantages of this system both computationally, and in terms of flexibility over various optimization problem forms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fioretto:24a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analyzing and Enhancing the Backward-Pass Convergence of Unrolled Optimization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Christopher, Jacob and Dinh, My H and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2312.17394}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2312.17394}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2023</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.sciencedirect.com/journal/electric-power-systems-research" rel="external nofollow noopener" target="_blank">EPSR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="MBF:epsr23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Gradient-enhanced physics-informed neural networks for power systems operational support</div>
        <!-- Author -->
        <div class="author">
        

        Mostafa Mohammadian, Kyri Baker, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Electric Power Systems Research</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.sciencedirect.com/science/article/pii/S0378779623004406" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The application of deep learning methods to speed up the challenging power system problems has recently shown very encouraging results. However, power system dynamics are not snapshot, steady-state operations. These dynamics must be considered to ensure that the optimal solutions provided by these models adhere to practical constraints to avoid frequency fluctuations and grid instabilities. Unfortunately, dynamic system models based on ordinary or partial differential equations are frequently unsuitable for direct application in control or state estimates due to their high computational costs. To address these challenges, this paper introduces a machine learning method to approximate the behavior of power systems dynamics in near real-time. The proposed framework is based on gradient-enhanced physics-informed neural networks (gPINNs) and encodes the underlying physical laws governing power systems. A key characteristic of the proposed gPINN is its ability to train without the need of generating expensive training data. The paper illustrates the potential of the proposed approach in both forward and inverse problems in a single-machine infinite bus system and a three-bus power network for predicting rotor angles and frequency, and uncertain parameters such as inertia and damping to showcase its potential for a range of power systems applications. The model exhibited high accuracy in predicting the variables, achieving a range of 0.533–4.092 and an average L2 relative error improvement of up to 13.30× compared to the PINN model. The computational performance of the proposed gPINN model was compared to a conventional solver, revealing a remarkable speed-up of 31 to 171 times faster in solving differential–algebraic systems of equations in power systems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MBF:epsr23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mohammadian, Mostafa and Baker, Kyri and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electric Power Systems Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{223}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{109551}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0378-7796}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.epsr.2023.109551}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0378779623004406}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TF:neurips23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Data Minimization at Inference Time</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/pdf?id=cZS5X3PLOR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2305.17593" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In domains with high stakes such as law, recruitment, and healthcare, learning models frequently rely on sensitive user data for inference, necessitating the complete set of features. This not only poses significant privacy risks for individuals but also demands substantial human effort from organizations to verify information accuracy. This paper asks whether it is necessary to use \emphall input features for accurate predictions at inference time. The paper demonstrates that, in a personalized setting, individuals may only need to disclose a small subset of their features without compromising decision-making accuracy. The paper also provides an efficient sequential algorithm to determine the appropriate attributes for each individual to provide. Evaluations across various learning tasks show that individuals can potentially report as little as 10% of their information while maintaining the same accuracy level as a model that employs the full set of user information.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TF:neurips23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Data Minimization at Inference Time}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DF:ccai23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Price-Aware Deep Learning for Electricity Markets</div>
        <!-- Author -->
        <div class="author">
        

        Vladimir Dvorkin, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.climatechange.ai/events/neurips2023" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2308.01436" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>While deep learning gradually penetrates operational planning, its inherent prediction errors may significantly affect electricity prices. This letter examines how prediction errors propagate into electricity prices, revealing notable pricing errors and their spatial disparity in congested power systems. To improve fairness, we propose to embed electricity market-clearing optimization as a deep learning layer. Differentiating through this layer allows for balancing between prediction and pricing errors, as oppose to minimizing prediction errors alone. This layer implicitly optimizes fairness and controls the spatial distribution of price errors across the system. We showcase the price-aware deep learning in the nexus of wind power forecasting and short-term electricity market clearing.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DF:ccai23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dvorkin, Vladimir and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Price-Aware Deep Learning for Electricity Markets}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.climatechange.ai/events/neurips2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2308.01436}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TZFvH:ijcai23" class="col-sm-8">
        <!-- Title -->
        <div class="title">SF-PATE: Scalable, Fair, and Private Aggregation of Teacher Ensembles</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, Keyu Zhu, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2023/56" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2204.05157" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A critical concern in data-driven processes is to build models whose outcomes do not discriminate against some demographic groups, including gender, ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of the group attributes is essential. However, in practice, these attributes may not be available due to legal and ethical requirements. To address this challenge, this paper studies a model that protects the privacy of the individuals’ sensitive information while also allowing it to learn non-discriminatory predictors. A key characteristic of the proposed model is to enable the adoption of off-the-selves and non-private fair models to create a privacy-preserving and fair model. The paper analyzes the relation between accuracy, privacy, and fairness, and the experimental evaluation illustrates the benefits of the proposed models on several prediction tasks. In particular, this proposal is the first to allow both scalable and accurate training of private and fair models for very large neural networks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TZFvH:ijcai23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Zhu, Keyu and Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SF-PATE:} Scalable, Fair, and Private Aggregation of Teacher Ensembles}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{501--509}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2023/56}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2023/56}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TF:ijcai23" class="col-sm-8">
        <!-- Title -->
        <div class="title">On the Fairness Impacts of Private Ensembles Models</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="https://ppai-workshop.github.io/" rel="external nofollow noopener" target="_blank">PPAI (AAAI 2022)</a></abbr>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2023/57" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2109.08630" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Private Aggregation of Teacher Ensembles (PATE) is a machine learning framework that enables the creation of private models through the combination of multiple "teacher" models and a "student" model. The student model learns to predict an output based on the voting of the teachers, and the resulting model satisfies differential privacy. PATE has been shown to be effective in creating private models in semi-supervised settings or when protecting data labels is a priority. This paper explores whether the use of PATE can result in unfairness, and demonstrates that it can lead to accuracy disparities among groups of individuals. The paper also analyzes the algorithmic and data properties that contribute to these disproportionate impacts, why these aspects are affecting different groups disproportionately, and offers recommendations for mitigating these effects.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TF:ijcai23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Fairness Impacts of Private Ensembles Models}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{510--518}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2023/57}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2023/57}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KVF:ijcai23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentiable Model Selection for Ensemble Learning</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, Vincenzo Di Vito, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2023/217" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Model selection is a strategy aimed at creating accurate and robust models by identifying the optimal model for classifying any particular input sample. This paper proposes a novel framework for differentiable selection of groups of models by integrating machine learning and combinatorial optimization. The framework is tailored for ensemble learning with a strategy that learns to combine the predictions of appropriately selected pre-trained ensemble models. It does so by modeling the ensemble learning task as a differentiable selection program trained end-to-end over a pretrained ensemble to optimize task performance. The proposed framework demonstrates its versatility and effectiveness, outperforming conventional and advanced consensus rules across a variety of classification tasks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KVF:ijcai23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Vito, Vincenzo Di and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentiable Model Selection for Ensemble Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1954--1962}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2023/217}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2023/217}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KDF:ijcai23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Backpropagation of Unrolled Solvers with Folded Optimization</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, My H. Dinh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2023/218" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2301.12047" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which typically lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the operations of an iterative solver. While flexible and general, unrolling can encounter accuracy and efficiency issues in practice. These issues can be avoided by analytical differentiation of the optimization, but current frameworks impose rigid requirements on the optimization problem’s form. This paper provides theoretical insights into the backward pass of unrolled optimization, leading to a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings. Experiments over various model-based learning tasks demonstrate the advantages of the approach both computationally and in terms of enhanced expressiveness.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KDF:ijcai23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Dinh, My H. and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Backpropagation of Unrolled Solvers with Folded Optimization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1963--1970}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2023/218}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2023/218}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KVF:aamas23" class="col-sm-8">
        <!-- Title -->
        <div class="title">End-to-End Optimization and Learning for Multiagent Ensembles</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, Vincenzo Di Vito, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://dl.acm.org/doi/10.5555/3545946.3599019" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2211.00251" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Ensemble learning is an important class of algorithms aiming at creating accurate machine learning models by combining predictions from individual agents. A key challenge for the design of these models is to create effective rules to combine individual predictions for any particular input sample. This paper proposes a unique integration of constrained optimization and learning to derive specialized consensus rules. The paper shows how to derive the ensemble learning task as end-to-end training of a discrete subset selection module. Results over standard benchmarks demonstrate an ability to substantially outperform conventional consensus rules in a variety of settings.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KVF:aamas23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Vito, Vincenzo Di and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Optimization and Learning for Multiagent Ensembles}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2613--2615}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.5555/3545946.3599019}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5555/3545946.3599019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ISGT</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DFMB:isgt23" class="col-sm-8">
        <!-- Title -->
        <div class="title">An Analysis of the Reliability of AC Optimal Power Flow Deep Learning Proxies</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, <em>Ferdinando Fioretto</em>, Mostafa Mohammadian, and Kyri Baker</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In IEEE PES Innovative Smart Grid Technologies</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieee-isgt-latam.org" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2111.11168" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Optimal Power Flow (OPF) is a fundamental problem in power systems. It is computationally challenging and a recent line of research has proposed the use of Deep Neural Networks (DNNs) to find OPF approximations at vastly reduced runtimes when compared to those obtained by classical optimization methods. While these works show encouraging results in terms of accuracy and runtime, little is known on why these models can predict OPF solutions accurately, as well as about their robustness. This paper provides a step forward to address this knowledge gap. The paper connects the volatility of the outputs of the generators to the ability of a learning model to approximate them, it sheds light on the characteristics affecting the DNN models to learn good predictors, and it proposes a new model that exploits the observations made by this paper to produce accurate and robust OPF predictions.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DFMB:isgt23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Fioretto, Ferdinando and Mohammadian, Mostafa and Baker, Kyri}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Analysis of the Reliability of AC Optimal Power Flow Deep Learning Proxies}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE} PES Innovative Smart Grid Technologies}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieee-isgt-latam.org}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DF:23" class="col-sm-8">
        <!-- Title -->
        <div class="title">Context-Aware Differential Privacy for Language Modeling</div>
        <!-- Author -->
        <div class="author">
        

        My H. Dinh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2023
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://arxiv.org/abs/2301.12288" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The remarkable ability of language models (LMs) has also brought challenges at the interface of AI and security. A critical challenge pertains to how much information these models retain and leak about the training data. This is particularly urgent as the typical development of LMs relies on huge, often highly sensitive data, such as emails and chat logs. To contrast this shortcoming, this paper introduces Context-Aware Differentially Private Language Model (CADP-LM) , a privacy-preserving LM framework that relies on two key insights: First, it utilizes the notion of \emphcontext to define and audit the potentially sensitive information. Second, it adopts the notion of Differential Privacy to protect sensitive information and characterize the privacy leakage. A unique characteristic of CADP-LM is its ability to target the protection of sensitive sentences and contexts only, providing a highly accurate private model. Experiments on a variety of datasets and settings demonstrate these strengths of CADP-LM.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DF:23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dinh, My H. and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Context-Aware Differential Privacy for Language Modeling}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2301.12288}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2301.12288}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2022</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.jair.org/index.php/jair" rel="external nofollow noopener" target="_blank">JAIR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="HFHYY:jairZ22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Proactive Dynamic Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        Khoi D. Hoang, <em>Ferdinando Fioretto</em>, Ping Hou, William Yeoh, Makoto Yokoo, and Roie Zivan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1613/jair.1.13499" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool for modeling multi-agent coordination problems. To solve DCOPs in a dynamic environment, Dynamic DCOPs (D-DCOPs) have been proposed to model the inherent dynamism present in many coordination problems. D-DCOPs solve a sequence of static problems by reacting to changes in the environment as the agents observe them. Such reactive approaches ignore knowledge about future changes of the problem. To overcome this limitation, we introduce Proactive Dynamic DCOPs (PD-DCOPs), a novel formalism to model D-DCOPs in the presence of exogenous uncertainty. In contrast to reactive approaches, PD-DCOPs are able to explicitly model possible changes of the problem and take such information into account when solving the dynamically changing problem in a proactive manner. The additional expressivity of this formalism allows it to model a wider variety of distributed optimization problems. Our work presents both theoretical and practical contributions that advance current dynamic DCOP models: (i) We introduce Proactive Dynamic DCOPs (PD-DCOPs), which explicitly model how the DCOP will change over time; (ii) We develop exact and heuristic algorithms to solve PD-DCOPs in a proactive manner; (iii) We provide theoretical results about the complexity of this new class of DCOPs; and (iv) We empirically evaluate both proactive and reactive algorithms to determine the trade-offs between the two classes. The final contribution is important as our results are the first that identify the characteristics of the problems that the two classes of algorithms excel in.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">HFHYY:jairZ22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Khoi D. and Fioretto, Ferdinando and Hou, Ping and Yeoh, William and Yokoo, Makoto and Zivan, Roie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Proactive Dynamic Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{74}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{179--225}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1613/jair.1.13499}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1613/jair.1.13499}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="TFKN:neurips22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Pruning has a disparate impact on model accuracy</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, <em>Ferdinando Fioretto</em>, Jung-Eun Kim, and Rakshit Naidu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Spotlight</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=11nMVZK0WYM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2205.13574" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Network pruning is a widely-used compression technique that is able to significantly scale down overparameterized models with minimal loss of accuracy. This paper shows that pruning may create or exacerbate disparate impacts. The paper sheds light on the factors to cause such disparities, suggesting differences in gradient norms and distance to decision boundary across groups to be responsible for this critical issue. It analyzes these factors in detail, providing both theoretical and empirical support, and proposes a simple, yet effective, solution that mitigates the disparate impacts caused by pruning.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TFKN:neurips22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Fioretto, Ferdinando and Kim, Jung-Eun and Naidu, Rakshit}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pruning has a disparate impact on model accuracy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=11nMVZK0WYM}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KFH:aaai22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Fast Approximations for Job Shop Scheduling: A Lagrangian Dual Deep Learning Method</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20685" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2110.06365" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Jobs Shop Scheduling problem (JSP) is a canonical combinatorial optimization problem that is routinely solved for a variety of industrial purposes. It models the optimal scheduling of multiple sequences of tasks, each under a fixed order of operations, in which individual tasks require exclusive access to a predetermined resource for a specified processing time. The problem is NP-hard and computationally challenging even for medium-sized instances. Motivated by the increased stochasticity in production chains, this paper explores a deep learning approach to deliver efficient and accurate approximations to the JSP. In particular, this paper proposes the design of a deep neural network architecture to exploit the problem structure, its integration with Lagrangian duality to capture the problem constraints, and a post-processing optimization, to guarantee solution feasibility. The resulting method, called JSP-DNN, is evaluated on hard JSP instances from the JSPLIB benchmark library and is shown to produce JSP approximations of high quality at negligible computational costs.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KFH:aaai22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast Approximations for Job Shop Scheduling: {A} Lagrangian Dual Deep Learning Method}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7239--7246}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/20685}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="ZFH:ijcai22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Post-processing of Differentially Private Data: A Fairness Perspective</div>
        <!-- Author -->
        <div class="author">
        

        Keyu Zhu, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2022/559" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2201.09425" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Post-processing immunity is a fundamental property of differential privacy: it enables arbitrary data-independent transformations to differentially private outputs without affecting their privacy guarantees. Post-processing is routinely applied in data-release applications, including census data, which are then used to make allocations with substantial societal impacts. This paper shows that post-processing causes disparate impacts on individuals or groups and analyzes two critical settings: the release of differentially private datasets and the use of such private datasets for downstream decisions, such as the allocation of funds informed by US Census data. In the first setting, the paper proposes tight bounds on the unfairness for traditional post-processing mechanisms, giving a unique tool to decision makers to quantify the disparate impacts introduced by their release. In the second setting, this paper proposes a novel post-processing mechanism that is (approximately) optimal under different fairness metrics, either reducing fairness issues substantially or reducing the cost of privacy. The theoretical analysis is complemented with numerical simulations on Census data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZFH:ijcai22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Keyu and Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Post-processing of Differentially Private Data: {A} Fairness Perspective}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4029--4035}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2022/559}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2022/559}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FHZ:ijcai22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy and Fairness in Decisions and Learning Tasks: A Survey</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Cuong Tran, Pascal Van Hentenryck, and Keyu Zhu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2022/766" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2202.08187" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper surveys the recent work in the intersection of differential privacy (DP) and fairness. It focuses on surveying the work observing that DP systems may exacerbate bias and disparate impacts for different groups of individuals. The survey reviews the conditions under which privacy and fairness may be aligned or contrasting goals, analyzes how and why DP exacerbates bias and unfairness in decision problems and learning tasks, and reviews the available solutions to mitigate the fairness issues arising in DP systems. The survey provides a unified understanding of the main challenges and potential risks arising when deploying privacy-preserving machine learning or decisions making tasks under a fairness lens.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FHZ:ijcai22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Tran, Cuong and Hentenryck, Pascal Van and Zhu, Keyu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy and Fairness in Decisions and Learning Tasks: {A} Survey}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5470--5477}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2022/766}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2022/766}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Early Career Spotlight</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="F:ijcai22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Integrating Machine Learning and Optimization to Boost Decision Making</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Early Career Spotlight</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2022/815" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper presents a conceptual review of our recent advancements in the integration of machine learning and optimization. It focuses on describing new hybrid machine learning and optimization methods to predict fast, approximate, solutions to combinatorial problems and to enable structural logical inference.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F:ijcai22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Integrating Machine Learning and Optimization to Boost Decision Making}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5808--5812}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2022/815}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2022/815}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">WWW</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KFHZ:WWW22" class="col-sm-8">
        <!-- Title -->
        <div class="title">End-to-End Learning for Fair Ranking Systems</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, and Ziwei Zhu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In The ACM Web Conference</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1145/3485447.3512247" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2111.10723" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The learning-to-rank problem aims at ranking items to maximize exposure of those most relevant to a user query. A desirable property of such ranking systems is to guarantee some notion of fairness among specified item groups. While fairness has recently been considered in the context of learning-to-rank systems, current methods cannot provide guarantees on the fairness of the predicted rankings. This paper addresses this gap and introduces Smart Predict and Optimize for Fair Ranking (SPOFR), an integrated optimization and learning framework for fairness-constrained learning to rank. The end-to-end SPOFR framework includes a constrained optimization sub-model and produces ranking policies that are guaranteed to satisfy fairness constraints, while allowing for fine control of the fairness-utility tradeoff. SPOFR is shown to significantly improve on current state-of-the-art fair learning-to-rank systems with respect to established performance metrics.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KFHZ:WWW22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Fioretto, Ferdinando and Hentenryck, Pascal Van and Zhu, Ziwei}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Learning for Fair Ranking Systems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The {ACM} Web Conference}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3520--3530}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3485447.3512247}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3485447.3512247}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PMAPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="MRHF:pmaps22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially-Private Heat and Electricity Markets Coordination</div>
        <!-- Author -->
        <div class="author">
        

        Lesia Mitridati, Emma Romei, Gabriela Hug, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Probabilistic Methods Applied to Power Systems</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Sector coordination between heat and electricity systems has been identified has an energy-efficient and cost-effective way to transition towards a more sustainable energy system. However, the coordination of sequential markets relies on the exchange of sensitive information between the market operators, namely time series of consumers’ loads. To address the privacy concerns arising from this exchange, this paper introduces a novel privacy-preserving Stackelberg mechanism (w-PPSM) which generates differentially-private data streams with high fidelity. The proposed w-PPSM enforces the feasibility and fidelity of the privacy-preserving data with respect to the original problem through a post-processing phase in order to achieve a close-to-optimal coordination between the markets. Multiple numerical simulations in a realistic energy system demonstrate the effectiveness of the w-PPSM, which achieves up to two orders of magnitude reduction in the cost of privacy compared to a traditional differentially-private mechanism.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MRHF:pmaps22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mitridati, Lesia and Romei, Emma and Hug, Gabriela and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially-Private Heat and Electricity Markets Coordination}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Probabilistic Methods Applied to Power Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/PMAPS53380.2022.9810564}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PMAPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="MBDF:pmaps22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Solutions for Intertemporal Power Systems Optimization with Recurrent Neural Networks</div>
        <!-- Author -->
        <div class="author">
        

        Mostafa Mohammadian, Kyri Baker, My H. Dinh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Probabilistic Methods Applied to Power Systems</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning mappings between system loading and optimal dispatch solutions has been a recent topic of interest in the power systems and machine learning communities. However, previous works have ignored practical power system constraints such as generator ramp limits and other intertemporal requirements. Additionally, optimal power flow runs are not performed independently of previous timesteps - in most cases, an OPF solution representing the current state of the system is heavily related to the OPF solution from previous timesteps. In this paper, we train a recurrent neural network, which embeds natural relationships between timesteps, to predict the optimal solution of convex power systems optimization problems with intertemporal constraints. In contrast to traditional forecasting methods, the computational benefits from this technique can allow operators to rapidly simulate forecasts of system operation and corresponding optimal solutions to provide a more comprehensive view of future system states.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MBDF:pmaps22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mohammadian, Mostafa and Baker, Kyri and Dinh, My H. and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Solutions for Intertemporal Power Systems Optimization with Recurrent Neural Networks}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Probabilistic Methods Applied to Power Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/PMAPS53380.2022.9810638}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DFvHPK:22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-Preserving Convex Optimization: When Differential Privacy Meets Stochastic Programming</div>
        <!-- Author -->
        <div class="author">
        

        Vladimir Dvorkin, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, Pierre Pinson, and Jalal Kazempour</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2006.12338" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2209.14152" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Convex optimization finds many real-life applications, where - optimized on real data - optimization results may expose private data attributes (e.g., individual health records, commercial information, etc.), thus leading to privacy breaches. To avoid these breaches and formally guarantee privacy to optimization data owners, we develop a new privacy-preserving perturbation strategy for convex optimization programs by combining stochastic (chance-constrained) programming and differential privacy. Unlike standard noise-additive strategies, which perturb either optimization data or optimization results, we express the optimization variables as functions of the random perturbation using linear decision rules; we then optimize these rules to accommodate the perturbation within the problem’s feasible region by enforcing chance constraints. This way, the perturbation is feasible and makes different, yet adjacent in the sense of a given distance function, optimization datasets statistically similar in randomized optimization results, thereby enabling probabilistic differential privacy guarantees. The chance-constrained optimization additionally internalizes the conditional value-at-risk measure to model the tolerance towards the worst-case realizations of the optimality loss with respect to the non-private solution. We demonstrate the privacy properties of our perturbation strategy analytically and through optimization and machine learning applications.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DFvHPK:22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dvorkin, Vladimir and Fioretto, Ferdinando and Hentenryck, Pascal Van and Pinson, Pierre and Kazempour, Jalal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy-Preserving Convex Optimization: When Differential Privacy Meets Stochastic Programming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2006.12338}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KFS:22" class="col-sm-8">
        <!-- Title -->
        <div class="title">Deadwooding: Robust Global Pruning for Deep Neural Networks</div>
        <!-- Author -->
        <div class="author">
        

        Sawinder Kaur, <em>Ferdinando Fioretto</em>, and Asif Salekin</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2022
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2202.05226" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2202.05226" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The ability of Deep Neural Networks to approximate highly complex functions is key to their success. This benefit, however, comes at the expense of a large model size, which challenges its deployment in resource-constrained environments. Pruning is an effective technique used to limit this issue, but often comes at the cost of reduced accuracy and adversarial robustness. This paper addresses these shortcomings and introduces Deadwooding, a novel global pruning technique that exploits a Lagrangian Dual method to encourage model sparsity while retaining accuracy and ensuring robustness. The resulting model is shown to significantly outperform the state-of-the-art studies in measures of robustness and accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">KFS:22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kaur, Sawinder and Fioretto, Ferdinando and Salekin, Asif}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deadwooding: Robust Global Pruning for Deep Neural Networks}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2202.05226}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.sciencedirect.com/journal/artificial-intelligence" rel="external nofollow noopener" target="_blank">AIJ</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Invited in the IJCAI-21 Journal Track</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvHZ:AIJ21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy of Hierarchical Census Data: An Optimization Approach</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, and Keyu Zhu</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Artificial Intelligence Journal</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Invited in the IJCAI-21 Journal Track</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1016/j.artint.2021.103475" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2006.15673" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper is motivated by applications of a Census Bureau interested in releasing aggregate socio-economic data about a large population without revealing sensitive information about any individual. The released information can be the number of individuals living alone, the number of cars they own, or their salary brackets. Recent events have identified some of the privacy challenges faced by these organizations [1]. To address them, this paper presents a novel differential-privacy mechanism for releasing hierarchical counts of individuals. The counts are reported at multiple granularities (e.g., the national, state, and county levels) and must be consistent across all levels. The core of the mechanism is an optimization model that redistributes the noise introduced to achieve differential privacy in order to meet the consistency constraints between the hierarchical levels. The key technical contribution of the paper shows that this optimization problem can be solved in polynomial time by exploiting the structure of its cost functions. Experimental results on very large, real datasets show that the proposed mechanism provides improvements of up to two orders of magnitude in terms of computational efficiency and accuracy with respect to other state-of-the-art techniques.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FvHZ:AIJ21</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy of Hierarchical Census Data: An Optimization Approach}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and {Van Hentenryck}, Pascal and Zhu, Keyu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Artificial Intelligence Journal}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{296}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103475}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.artint.2021.103475}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.artint.2021.103475}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=59" rel="external nofollow noopener" target="_blank">TPWRS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2022 TPWRS Best Paper Award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="DFvHPK:tpwrs21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially Private Optimal Power Flow for Distribution Grids</div>
        <!-- Author -->
        <div class="author">
        

        Vladimir Dvorkin, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, Pierre Pinson, and Jalal Kazempour</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Power Systems</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2022 TPWRS Best Paper Award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ieeexplore.ieee.org/document/9226144" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2004.03921" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Although distribution grid customers are obliged to share their consumption data with distribution system operators (DSOs), a possible leakage of this data is often disregarded in operational routines of DSOs. This paper introduces a privacy-preserving optimal power flow (OPF) mechanism for distribution grids that secures customer privacy from unauthorised access to OPF solutions, e.g., current and voltage measurements. The mechanism is based on the framework of differential privacy that allows to control the participation risks of individuals in a dataset by applying a carefully calibrated noise to the output of a computation. Unlike existing private mechanisms, this mechanism does not apply the noise to the optimization parameters or its result. Instead, it optimizes OPF variables as affine functions of the random noise, which weakens the correlation between the grid loads and OPF variables. To ensure feasibility of the randomized OPF solution, the mechanism makes use of chance constraints enforced on the grid limits. The mechanism is further extended to control the optimality loss induced by the random noise, as well as the variance of OPF variables. The paper shows that the differentially private OPF solution does not leak customer loads up to specified parameters.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DFvHPK:tpwrs21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dvorkin, Vladimir and Fioretto, Ferdinando and {Van Hentenryck}, Pascal and Pinson, Pierre and Kazempour, Jalal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially Private Optimal Power Flow for Distribution Grids}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Power Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2186--2196}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPWRS.2020.3031314}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9226144}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TMF:neurips21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially Private Empirical Risk Minimization under the Fairness Lens</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, My H. Dinh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=7EFdodSWee4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2106.02674" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Differential Privacy (DP) is an important privacy-enhancing technology for private machine learning systems. It allows to measure and bound the risk associated with an individual participation in a computation. However, it was recently observed that DP learning systems may exacerbate bias and unfairness for different groups of individuals. This paper builds on these important observations and sheds light on the causes of the disparate impacts arising in the problem of differentially private empirical risk minimization. It focuses on the accuracy disparity arising among groups of individuals in two well-studied DP learning methods: output perturbation and differentially private stochastic gradient descent. The paper analyzes which data and model properties are responsible for the disproportionate impacts, why these aspects are affecting different groups disproportionately and proposes guidelines to mitigate these effects. The proposed approach is evaluated on several datasets and settings.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TMF:neurips21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and H.~Dinh, My and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially Private Empirical Risk Minimization under the Fairness Lens}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{27555--27565}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=7EFdodSWee4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">NeurIPS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KFvH:neurips21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Hard Optimization Problems: A Data Generation Perspective</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Advances in Neural Information Processing Systems</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openreview.net/forum?id=2zO2lb7ykMD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2106.02601" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Optimization problems are ubiquitous in our societies and are present in almost every segment of the economy. Most of these optimization problems are NP-hard and computationally demanding, often requiring approximate solutions for large-scale instances. Machine learning frameworks that learn to approximate solutions to such hard optimization problems are a potentially promising avenue to address these difficulties, particularly when many closely related problem instances must be solved repeatedly. Supervised learning frameworks can train a model using the outputs of pre-solved instances. However, when the outputs are themselves approximations, when the optimization problem has symmetric solutions, and/or when the solver uses randomization, solutions to closely related instances may exhibit large differences and the learning task can become inherently more difficult. This paper demonstrates this critical challenge, connects the volatility of the training data to the ability of a model to approximate it, and proposes a method for producing (exact or approximate) solutions to optimization problems that are more amenable to supervised learning tasks. The effectiveness of the method is tested on hard non-linear nonconvex and discrete combinatorial problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KFvH:neurips21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Fioretto, Ferdinando and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Hard Optimization Problems: A Data Generation Perspective}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{24981--24992}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=2zO2lb7ykMD}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TFvH:aaai21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="https://ppai-workshop.github.io/" rel="external nofollow noopener" target="_blank">PPAI (AAAI 2021)</a></abbr>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17193" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2009.12562" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A critical concern in data-driven decision making is to build models whose outcomes do not discriminate against some demographic groups, including gender, ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of the sensitive attributes is essential, while, in practice, these attributes may not be available due to legal and ethical requirements. To address this challenge, this paper studies a model that protects the privacy of the individuals’ sensitive information while also allowing it to learn non-discriminatory predictors. The method relies on the notion of differential privacy and the use of Lagrangian duality to design neural networks that can accommodate fairness constraints while guaranteeing the privacy of sensitive attributes. The paper analyses the tension between accuracy, privacy, and fairness and the experimental evaluation illustrates the benefits of the proposed model on several prediction tasks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TFvH:aaai21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Fioretto, Ferdinando and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially Private and Fair Deep Learning: {A} Lagrangian Dual Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9932--9939}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17193}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="ZHF:aaai21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Bias and Variance of Post-processing in Differential Privacy</div>
        <!-- Author -->
        <div class="author">
        

        Keyu Zhu, Pascal Van Hentenryck, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17333" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2010.04327" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Post-processing immunity is a fundamental property of differential privacy: it enables the application of arbitrary data-independent transformations to the results of differentially private outputs without affecting their privacy guarantees. When query outputs must satisfy domain constraints, post-processing can be used to project them back onto the feasibility region. Moreover, when the feasible region is convex, a widely adopted class of post-processing steps is also guaranteed to improve accuracy. Post-processing has been applied successfully in many applications including census data, energy systems, and mobility. However, its effects on the noise distribution is poorly understood: It is often argued that post-processing may introduce bias and increase variance. This paper takes a first step towards understanding the properties of post-processing. It considers the release of census data and examines, both empirically and theoretically, the behavior of a widely adopted class of post-processing functions.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZHF:aaai21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Keyu and Hentenryck, Pascal Van and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bias and Variance of Post-processing in Differential Privacy}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11177--11184}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/17333}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2022 Caspar Bowden PET award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="TFHY:ijcai21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Decision Making with Differential Privacy under a Fairness Lens</div>
        <!-- Author -->
        <div class="author">
        

        Cuong Tran, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, and Zhiyan Yao</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="">TPDP (NeurIPS 2021)</a></abbr>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2022 Caspar Bowden PET award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2021/78" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2105.07513" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Agencies, such as the U.S. Census Bureau, release data sets and statistics about groups of individuals that are used as input to a number of critical decision processes. To conform to privacy and confidentiality requirements, these agencies are often required to release privacy-preserving versions of the data. This paper studies the release of differentially private data sets and analyzes their impact on some critical resource allocation tasks under a fairness perspective. The paper shows that, when the decisions take as input differentially private data, the noise added to achieve privacy disproportionately impacts some groups over others. The paper analyzes the reasons for these disproportionate impacts and proposes guidelines to mitigate these effects. The proposed approaches are evaluated on critical decision problems that use differentially private census data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TFHY:ijcai21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tran, Cuong and Fioretto, Ferdinando and {Van Hentenryck}, Pascal and Yao, Zhiyan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decision Making with Differential Privacy under a Fairness Lens}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{560--566}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2021/78}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2021/78}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="KFHW:ijcai21" class="col-sm-8">
        <!-- Title -->
        <div class="title">End-to-End Constrained Optimization Learning: A Survey</div>
        <!-- Author -->
        <div class="author">
        

        James Kotary, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, and Bryan Wilder</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2021/610" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2103.16378" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper surveys the recent attempts at leveraging machine learning to solve constrained optimization problems. It focuses on surveying the work on integrating combinatorial solvers and optimization methods with machine learning architectures. These approaches hold the promise to develop new hybrid machine learning and optimization methods to predict fast, approximate, solutions to combinatorial problems and to enable structural logical inference. This paper presents a conceptual review of the recent advancements in this emerging area.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KFHW:ijcai21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kotary, James and Fioretto, Ferdinando and {Van Hentenryck}, Pascal and Wilder, Bryan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{End-to-End Constrained Optimization Learning: {A} Survey}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4475--4482}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2021/610}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2021/610}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="NTF:aamas21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-Preserving and Accountable Multi-agent Learning</div>
        <!-- Author -->
        <div class="author">
        

        Anudit Nagar, Cuong Tran, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.ifaamas.org/Proceedings/aamas2021/pdfs/p1605.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2106.01242" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Distributed multi-agent learning enables agents to cooperatively train a model without requiring to share their datasets. While this setting ensures some level of privacy, it has been shown that, even when data is not directly shared, the training process is vulnerable to privacy attacks including data reconstruction and model inversion attacks. Additionally, malicious agents that train on inverted labels or random data, may arbitrarily weaken the accuracy of the global model. This paper addresses these challenges and presents Privacy-preserving and Accountable Distributed Learning (PA-DL), a fully decentralized framework that relies on Differential Privacy to guarantee strong privacy protection of the agents data, and Ethereum smart contracts to ensure accountability.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NTF:aamas21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nagar, Anudit and Tran, Cuong and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy-Preserving and Accountable Multi-agent Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1605--1606}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5555/3463952.3464174}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F:cp21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained-Based Differential Privacy (Invited Talk)</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.4230/LIPIcs.CP.2021.2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F:cp21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained-Based Differential Privacy (Invited Talk)}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{LIPIcs}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{210}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2:1--2:1}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Schloss Dagstuhl}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.4230/LIPIcs.CP.2021.2}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.4230/LIPIcs.CP.2021.2}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="MFvH:21" class="col-sm-8">
        <!-- Title -->
        <div class="title">Load Embeddings for Scalable AC-OPF Learning</div>
        <!-- Author -->
        <div class="author">
        

        Terrence W. K. Mak, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2021
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2101.03973" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The AC Optimal Power Flow (AC-OPF) problem is a core building block in electrical transmission system. It seeks the most economical active and reactive generation dispatch to meet demands while satisfying transmission operational limits. It is often solved repeatedly, especially in regions with large penetration of wind farms to avoid violating operational and physical limits. Recent work has shown that deep learning techniques have huge potential in providing accurate approximations of AC-OPF solutions. However, deep learning approaches often suffer from scalability issues, especially when applied to real life power grids. This paper focuses on the scalability limitation and proposes a load compression embedding scheme to reduce training model sizes using a 3-step approach. The approach is evaluated experimentally on large-scale test cases from the PGLib, and produces an order of magnitude improvements in training convergence and prediction accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MFvH:21</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mak, Terrence W. K. and Fioretto, Ferdinando and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Load Embeddings for Scalable {AC-OPF} Learning}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2101.03973}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2101.03973}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2020</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">AI Mag.</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/aim/BangBBCCCCCDDEF20" class="col-sm-8">
        <!-- Title -->
        <div class="title">The Association for the Advancement of Artificial Intelligence 2020 Workshop Program</div>
        <!-- Author -->
        <div class="author">
        

        Grace Bang, Guy Barash, Ryan Beal, Jacques Calı̀, Mauricio Castillo-Effen, Xin Cynthia Chen, Niyati Chhaya, Rachel Cummings, Rohan Dhoopar, Sebastijan Dumancic, Huáscar Espinoza, Eitan Farchi, <em>Ferdinando Fioretto</em>, Raquel Fuentetaja, Christopher William Geib, Odd Erik Gundersen, José Hernández-Orallo, Xiaowei Huang, Kokil Jaidka, Sarah Keren, Seokhwan Kim, Michel Galley, Xiaomo Liu, Tyler Lu, Zhiqiang Ma, Richard Mallah, John A. McDermid, Martin Michalowski, Reuth Mirsky, Seán Ó hÉigeartaigh, Deepak Ramachandran, Javier Segovia Aguas, Onn Shehory, Arash Shaban-Nejad, Vered Shwartz, Siddharth Srivastava, Kartik Talamadupula, Jian Tang, Pascal Van Hentenryck, Dell Zhang, and Jian Zhang</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>AI Magazine</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1609/aimag.v41i4.7398" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/aim/BangBBCCCCCDDEF20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bang, Grace and Barash, Guy and Beal, Ryan and Cal{\`{\i}}, Jacques and Castillo{-}Effen, Mauricio and Chen, Xin Cynthia and Chhaya, Niyati and Cummings, Rachel and Dhoopar, Rohan and Dumancic, Sebastijan and Espinoza, Hu{\'{a}}scar and Farchi, Eitan and Fioretto, Ferdinando and Fuentetaja, Raquel and Geib, Christopher William and Gundersen, Odd Erik and Hern{\'{a}}ndez{-}Orallo, Jos{\'{e}} and Huang, Xiaowei and Jaidka, Kokil and Keren, Sarah and Kim, Seokhwan and Galley, Michel and Liu, Xiaomo and Lu, Tyler and Ma, Zhiqiang and Mallah, Richard and McDermid, John A. and Michalowski, Martin and Mirsky, Reuth and h{\'{E}}igeartaigh, Se{\'{a}}n {\'{O}} and Ramachandran, Deepak and Aguas, Javier Segovia and Shehory, Onn and Shaban{-}Nejad, Arash and Shwartz, Vered and Srivastava, Siddharth and Talamadupula, Kartik and Tang, Jian and Hentenryck, Pascal Van and Zhang, Dell and Zhang, Jian}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Association for the Advancement of Artificial Intelligence 2020 Workshop Program}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{AI} Magazine}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{41}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100--114}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1609/aimag.v41i4.7398}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1609/aimag.v41i4.7398}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165411" rel="external nofollow noopener" target="_blank">TSG</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FMH:tsg20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy for Power Grid Obfuscation</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Terrence W. K. Mak, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Smart Grids</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1109/TSG.2019.2936712" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1901.06949" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The availability of high-fidelity energy networks brings significant value to academic and commercial research. However, such releases also raise fundamental concerns related to privacy and security as they can reveal sensitive commercial information and expose system vulnerabilities. This paper investigates how to release the data for power networks where the parameters of transmission lines and transformers are obfuscated. It does so by using the framework of Differential Privacy (DP), that provides strong privacy guarantees and has attracted significant attention in recent years. Unfortunately, simple DP mechanisms often result in AC-infeasible networks. To address these concerns, this paper presents a novel differentially private mechanism that guarantees AC-feasibility and largely preserves the fidelity of the obfuscated power network. Experimental results also show that the obfuscation significantly reduces the potential damage of an attack carried by exploiting the released dataset.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FMH:tsg20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Mak, Terrence W. K. and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy for Power Grid Obfuscation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Smart Grids}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1356--1366}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TSG.2019.2936712}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSG.2019.2936712}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=59" rel="external nofollow noopener" target="_blank">TPWRS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2021 TPWRS Best Paper Award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="Mak:TPS20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-Preserving Power System Obfuscation: A Bilevel Optimization Approach</div>
        <!-- Author -->
        <div class="author">
        

        Terrence W. K. Mak, <em>Ferdinando Fioretto</em>, Lyndon Shi, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Power Systems</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">2021 TPWRS Best Paper Award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2001.09508" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper considers the problem of releasing optimal power flow (OPF) test cases that preserve the privacy of customers (loads) using the notion of Differential Privacy. It is motivated by the observation that traditional differential privacy algorithms are not suitable for releasing privacy preserving OPF test cases: The added noise fundamentally changes the nature of the underlying optimization and often leads to test cases with no solutions. To remedy this limitation, the paper introduces the OPF Load Indistinguishability (OLI) problem, which guarantees load privacy while satisfying the OPF constraints and remaining close to the optimal dispatch cost. The paper introduces an exact mechanism, based on bilevel optimization, as well as three mechanisms that approximate the OLI problem accurately. These mechanisms enjoy desirable theoretical properties, and the computational experiments show that they produce orders of magnitude improvements over standard approaches on an extensive collection of test cases.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FMH:aaai20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Predicting AC Optimal Power Flows: Combining Deep Learning and Lagrangian Dual Methods</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Terrence W. K. Mak, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5403" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1909.10461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Optimal Power Flow (OPF) problem is a fundamental building block for the optimization of electrical power systems. It is nonlinear and nonconvex and computes the generator setpoints for power and voltage, given a set of load demands. It is often solved repeatedly under various conditions, either in real-time or in large-scale studies. This need is further exacerbated by the increasing stochasticity of power systems due to renewable energy sources in front and behind the meter. To address these challenges, this paper presents a deep learning approach to the OPF. The learning model exploits the information available in the similar states of the system (which is commonly available in practical applications), as well as a dual Lagrangian method to satisfy the physical and engineering constraints present in the OPF. The proposed model is evaluated on a large collection of realistic medium-sized power systems. The experimental results show that its predictions are highly accurate with average errors as low as 0.2%. Additionally, the proposed approach is shown to improve the accuracy of the widely adopted linear DC approximation by at least two orders of magnitude.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FMH:aaai20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Mak, Terrence W. K. and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predicting {AC} Optimal Power Flows: Combining Deep Learning and Lagrangian Dual Methods}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{630--637}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AAAI/article/view/5403}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FMH:ijcai20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy for Stackelberg Games</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Lesia Mitridati, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2020/481" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2002.00944" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces a differentially private (DP) mechanism to protect the information exchanged during the coordination of sequential and interdependent markets. This coordination represents a classic Stackelberg game and relies on the exchange of sensitive information between the system agents. The paper is motivated by the observation that the perturbation introduced by traditional DP mechanisms fundamentally changes the underlying optimization problem and even leads to unsatisfiable instances. To remedy such limitation, the paper introduces the Privacy-Preserving Stackelberg Mechanism (PPSM), a framework that enforces the notions of feasibility and fidelity of the privacy-preserving information to the original problem objective. PPSM complies with the notion of differential privacy and ensures that the outcomes of the privacy-preserving coordination mechanism are close-to-optimality for each agent. Experimental results on several gas and electricity market benchmarks based on a real case study demonstrate the effectiveness of the approach.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FMH:ijcai20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Mitridati, Lesia and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy for Stackelberg Games}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3480--3486}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2020/481}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2020/481}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvH:IJCAI20" class="col-sm-8">
        <!-- Title -->
        <div class="title">OptStream: Releasing Time Series Privately (Extended Abstract)</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2020
        </div>
        <!-- <div class="periodical">
          Appeared in JAIR 2019
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2020/722" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1808.01949" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many applications of machine learning and optimization operate on data streams. While these datasets are fundamental to fuel decision-making algorithms, often they contain sensitive information about individuals, and their usage poses significant privacy risks. Motivated by an application in energy systems, this paper presents OptStream, a novel algorithm for releasing differentially private data streams under the w-event model of privacy. OptStream is a 4-step procedure consisting of sampling, perturbation, reconstruction, and post-processing modules. First, the sampling module selects a small set of points to access in each period of interest. Then, the perturbation module adds noise to the sampled data points to guarantee privacy. Next, the reconstruction module reassembles non-sampled data points from the perturbed sample points. Finally, the post-processing module uses convex optimization over the privacy-preserving output of the previous modules, as well as the privacy-preserving answers of additional queries on the data stream, to improve accuracy by redistributing the added noise. OptStream is evaluated on a test case involving the release of a real data stream from the largest European transmission operator. Experimental results show that OptStream may not only improve the accuracy of state-of-the-art methods by at least one order of magnitude but also supports accurate load forecasting on the privacy-preserving data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FvH:IJCAI20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{OptStream: Releasing Time Series Privately (Extended Abstract)}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5135--5139}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2020/722}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2020/722}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Appeared in JAIR 2019}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ECML</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvHMTBL:ecml20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Lagrangian Duality for Constrained Deep Learning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, Terrence W. K. Mak, Cuong Tran, Federico Baldo, and Michele Lombardi</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Machine Learning</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-030-67670-4_8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2001.09394" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper explores the potential of Lagrangian duality for learning applications that feature complex constraints. Such constraints arise in many science and engineering domains, where the task amounts to learning optimization problems which must be solved repeatedly and include hard physical and operational constraints. The paper also considers applications where the learning task must enforce constraints on the predictor itself, either because they are natural properties of the function to learn or because it is desirable from a societal standpoint to impose them. This paper demonstrates experimentally that Lagrangian duality brings significant benefits for these applications. In energy domains, the combination of Lagrangian duality and deep learning can be used to obtain state-of-the-art results to predict optimal power flows, in energy systems, and optimal compressor settings, in gas networks. In transprecision computing, Lagrangian duality can complement deep learning to impose monotonicity constraints on the predictor without sacrificing accuracy. Finally, Lagrangian duality can be used to enforce fairness constraints on a predictor and obtain state-of-the-art results when minimizing disparate treatments.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FvHMTBL:ecml20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and {Van Hentenryck}, Pascal and Mak, Terrence W. K. and Tran, Cuong and Baldo, Federico and Lombardi, Michele}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lagrangian Duality for Constrained Deep Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12461}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{118--135}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-67670-4\_8}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-67670-4\_8}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PSCC</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="MFvH:pscc20" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-preserving obfuscation for distributed power systems</div>
        <!-- Author -->
        <div class="author">
        

        Terrence W.K. Mak, <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Electric Power Systems Research</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.sciencedirect.com/science/article/pii/S0378779620305216" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1910.04250" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper considers the problem of releasing privacy-preserving load data of a decentralized operated power system. The paper focuses on data used to solve Optimal Power Flow (OPF) problems and proposes a distributed algorithm that complies with the notion of Differential Privacy, a strong privacy framework used to bound the risk of re-identification. The problem is challenging since the application of traditional differential privacy mechanisms to the load data fundamentally  changes the nature of the underlying optimization problem and often leads to severe feasibility issues. The proposed differentially private distributed algorithm is based on the Alternating Direction Method of Multipliers (ADMM) and guarantees that the released privacy-preserving data retains high fidelity and satisfies the AC power flow constraints. Experimental results on a variety of OPF benchmarks demonstrate the effectiveness of the approach.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MFvH:pscc20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mak, Terrence W.K. and Fioretto, Ferdinando and {Van Hentenryck}, Pascal}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy-preserving obfuscation for distributed power systems}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electric Power Systems Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{189}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{106718}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0378-7796}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.epsr.2020.106718}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0378779620305216}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PRIMA</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TYF:prima20" class="col-sm-8">
        <!-- Title -->
        <div class="title">The Smart Appliance Scheduling Problem: A Bayesian Optimization Approach</div>
        <!-- Author -->
        <div class="author">
        

        Atena M. Tabakhi, William Yeoh, and <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Principles and Practice of Multi-Agent Systems</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-69322-0_7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Daily energy demand peaks induce high greenhouse gas emissions and are deleterious to the power grid operations. The autonomous and coordinated control of smart appliances in residential buildings represents an effective solution to reduce peak demands. This coordination problem is challenging as it involves, not only, scheduling devices to minimize energy peaks, but also to comply with user’ preferences. Prior work assumed these preferences to be fully specified and known a priori, which is, however, unrealistic. To remedy this limitation, this paper introduces a Bayesian optimization approach for smart appliance scheduling when the users’ satisfaction with a schedule must be elicited, and thus considered expensive to evaluate. The paper presents a set of ad-hoc energy-cost based acquisition functions to drive the Bayesian optimization problem to find schedules that maximize the user’s satisfaction. The experimental results demonstrate the effectiveness of the proposed energy-cost based acquisition functions which improve the algorithm’s performance up to 26%.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TYF:prima20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tabakhi, Atena M. and Yeoh, William and Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Smart Appliance Scheduling Problem: {A} Bayesian Optimization Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Principles and Practice of Multi-Agent Systems}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12568}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{100--115}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-030-69322-0_7}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-69322-0\_7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DFvHKP:20b" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differentially Private Convex Optimization with Feasibility Guarantees</div>
        <!-- Author -->
        <div class="author">
        

        Vladimir Dvorkin, <em>Ferdinando Fioretto</em>, Pascal Van Hentenryck, Jalal Kazempour, and Pierre Pinson</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2006.12338" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2006.12338" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper develops a novel differentially private framework to solve convex optimization problems with sensitive optimization data and complex physical or operational constraints. Unlike standard noise-additive algorithms, that act primarily on the problem data, objective or solution, and disregard the problem constraints, this framework requires the optimization variables to be a function of the noise and exploits a chance-constrained problem reformulation with formal feasibility guarantees. The noise is calibrated to provide differential privacy for identity and linear queries on the optimization solution. For many applications, including resource allocation problems, the proposed framework provides a trade-off between the expected optimality loss and the variance of optimization results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DFvHKP:20b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dvorkin, Vladimir and Fioretto, Ferdinando and Hentenryck, Pascal Van and Kazempour, Jalal and Pinson, Pierre}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentially Private Convex Optimization with Feasibility Guarantees}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2006.12338}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#808080"><a href="">ArXiv</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="CFMvH:20" class="col-sm-8">
        <!-- Title -->
        <div class="title">High-Fidelity Machine Learning Approximations of Large-Scale Optimal Power Flow</div>
        <!-- Author -->
        <div class="author">
        

        Minas Chatzos, <em>Ferdinando Fioretto</em>, Terrence W. K. Mak, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>CoRR</em>, 2020
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2006.16356" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/2006.16356" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The AC Optimal Power Flow (AC-OPF) is a key building block in many power system applications. It determines generator setpoints at minimal cost that meet the power demands while satisfying the underlying physical and operational constraints. It is non-convex and NP-hard, and computationally challenging for large-scale power systems. Motivated by the increased stochasticity in generation schedules and increasing penetration of renewable sources, this paper explores a deep learning approach to deliver highly efficient and accurate approximations to the AC-OPF. In particular, the paper proposes an integration of deep neural networks and Lagrangian duality to capture the physical and operational constraints. The resulting model, called OPF-DNN, is evaluated on real case studies from the French transmission system, with up to 3,400 buses and 4,500 lines. Computational results show that OPF-DNN produces highly accurate AC-OPF approximations whose costs are within 0.01% of optimality. OPF-DNN generates, in milliseconds, solutions that capture the problem constraints with high fidelity.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CFMvH:20</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chatzos, Minas and Fioretto, Ferdinando and Mak, Terrence W. K. and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High-Fidelity Machine Learning Approximations of Large-Scale Optimal Power Flow}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/2006.16356}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.jair.org/index.php/jair" rel="external nofollow noopener" target="_blank">JAIR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvH:jair19" class="col-sm-8">
        <!-- Title -->
        <div class="title">OptStream: Releasing Time Series Privately</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2019
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1613/jair.1.11583" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Many applications of machine learning and optimization operate on data streams. While these datasets are fundamental to fuel decision-making algorithms, often they contain sensitive information about individuals, and their usage poses significant privacy risks. Motivated by an application in energy systems, this paper presents OptStream, a novel algorithm for releasing differentially private data streams under the w-event model of privacy. OptStream is a 4-step procedure consisting of sampling, perturbation, reconstruction, and post-processing modules. First, the sampling module selects a small set of points to access in each period of interest. Then, the perturbation module adds noise to the sampled data points to guarantee privacy. Next, the reconstruction module re-assembles non-sampled data points from the perturbed sample points. Finally, the post-processing module uses convex optimization over the privacy-preserving output of the previous modules, as well as the privacy-preserving answers of additional queries on the data stream, to improve accuracy by redistributing the added noise. OptStream is evaluated on a test case involving the release of a real data stream from the largest European transmission operator. Experimental results show that OptStream may not only improve the accuracy of state-of-the-art methods by at least one order of magnitude but also supports accurate load forecasting on the privacy-preserving data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FvH:jair19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{OptStream: Releasing Time Series Privately}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{65}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{423--456}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1613/jair.1.11583}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1613/jair.1.11583}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://content.iospress.com/journals/intelligenza-artificiale/17/1" rel="external nofollow noopener" target="_blank">IA</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best AI*IA Dissertation in AI</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="FDP:ia19" class="col-sm-8">
        <!-- Title -->
        <div class="title">Distributed multi-agent optimization for smart grids and home automation</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Agostino Dovier, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Intelligenza Artificial</em>, 2019
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best AI*IA Dissertation in AI</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Distributed Constraint Optimization Problems (DCOPs) have emerged as one of the prominent multi-agent architectures to govern the agents’ autonomous behavior in a cooperative multi-agent system (MAS) where several agents coordinate with each other to optimize a global cost function taking into account their local preferences. They represent a powerful approach to the description and resolution of many practical problems. However, typical MAS applications are characterized by complex dynamics and interactions among a large number of entities, which translate into hard combinatorial problems, posing significant challenges from a computational and coordination standpoints. This paper reviews two methods to promote a hierarchical parallel model for solving DCOPs, with the aim of improving the performance of the DCOP algorithm. The first is a Multi-Variable Agent (MVA) DCOP decomposition, which exploits co-locality of an agent’s variables allowing the adoption of efficient centralized techniques to solve the subproblem of an agent. The second is the use of Graphics Processing Units (GPUs) to speed up a class of DCOP algorithms. Finally, exploiting these hierarchical parallel model, the paper presents two critical applications of DCOPs for demand response (DR) program in smart grids. The Multi-agent Economic Dispatch with Demand Response (EDDR), which provides an integrated approach to the economic dispatch and the DR model for power systems, and the Smart Home Device Scheduling (SHDS) problem, that formalizes the device scheduling and coordination problem across multiple smart homes to reduce energy peaks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FDP:ia19</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed multi-agent optimization for smart grids and home automation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Dovier, Agostino and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Intelligenza Artificial}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3233/IA-18003}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{67--87}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvH:aamas19" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-Preserving Federated Data Sharing</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2019
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=3331750" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Consider a set of agents with sensitive datasets who are interested in the same prediction task and would like to share their datasets without revealing private information. For instance, the agents may be medical centers with their own historical databases and the task may be the diagnosis of a rare form of a disease. This paper investigates whether sharing privacy-preserving versions of these datasets may improve the agent predictions. It proposes a Privacy-preserving Federated Data Sharing (PFDS) protocol that each agent can run locally to produce a privacy-preserving version of its original dataset. The PFDS protocol is evaluated on several standard prediction tasks and experimental results demonstrate the potential of sharing privacy- preserving datasets to produce accurate predictors.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FvH:aamas19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy-Preserving Federated Data Sharing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{638--646}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{International Foundation for Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=3331750}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Invited to Constraint journal - selected paper</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvH:cp19" class="col-sm-8">
        <!-- Title -->
        <div class="title">Differential Privacy of Hierarchical Census Data: An Optimization Approach</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2019
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Invited to Constraint journal - selected paper</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-030-30048-7_37" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper is motivated by applications of a Census Bureau interested in releasing aggregate socio-economic data about a large population without revealing sensitive information. The released information can be the number of individuals living alone, the number of cars they own, or their salary brackets. Recent events have identified some of the privacy challenges faced by these organizations. To address them, this paper presents a novel differential-privacy mechanism for releasing hierarchical counts of individuals satisfying a given property. The counts are reported at multiple granularities (e.g., the national, state, and county levels) and must be consistent across levels. The core of the mechanism is an optimization model that redistributes the noise introduced to attain privacy in order to meet the consistency constraints between the hierarchical levels. The key technical contribution of the paper shows that this optimization problem can be solved in polynomial time by exploiting the structure of its cost functions. Experimental results on very large, real datasets show that the proposed mechanism provides improvements up to two orders of magnitude in terms of computational efficiency and accuracy with respect to other state-of-the-art techniques.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FvH:cp19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differential Privacy of Hierarchical Census Data: An Optimization Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11802}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{639--655}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-30048-7\_37}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-30048-7\_37}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">IJCAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FMvH:ijcai19" class="col-sm-8">
        <!-- Title -->
        <div class="title">Privacy-Preserving Obfuscation of Critical Infrastructure Networks</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Terrence W. K. Mak, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Joint Conference on Artificial Intelligence</em>, 2019
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.24963/ijcai.2019/152" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1905.09778" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The paper studies how to release data about a critical infrastructure network (e.g., a power network or a transportation network) without disclosing sensitive information that can be exploited by malevolent agents, while preserving the realism of the network. It proposes a novel obfuscation mechanism that combines several privacy-preserving building blocks with a bi-level optimization model to significantly improve accuracy. The obfuscation is evaluated for both realism and privacy properties on real energy and transportation networks. Experimental results show the obfuscation mechanism substantially reduces the potential damage of an attack exploiting the released data to harm the real network.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FMvH:ijcai19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Mak, Terrence W. K. and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Kraus, Sarit}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy-Preserving Obfuscation of Critical Infrastructure Networks}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1086--1092}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2019/152}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2019/152}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2018</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.jair.org/index.php/jair" rel="external nofollow noopener" target="_blank">JAIR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FPY:jair18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Distributed Constraint Optimization Problems and Applications: A Survey</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Enrico Pontelli, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1613/jair.5565" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The field of Multi-Agent System (MAS) is an active area of research within Artificial Intelligence, with an increasingly important impact in industrial and other real-world applications. Within a MAS, autonomous agents interact to pursue personal interests and/or to achieve common objectives. Distributed Constraint Optimization Problems (DCOPs) have emerged as one of the prominent agent architectures to govern the agents’ autonomous behavior, where both algorithms and communication models are driven by the structure of the specific problem. During the last decade, several extensions to the DCOP model have enabled them to support MAS in complex, real-time, and uncertain environments. This survey aims at providing an overview of the DCOP model, giving a classification of its multiple extensions and addressing both resolution methods and applications that find a natural mapping within each class of DCOPs. The proposed classification suggests several future perspectives for DCOP extensions, and identifies challenges in the design of efficient resolution algorithms, possibly through the adaptation of strategies from different areas.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FPY:jair18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Pontelli, Enrico and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Distributed Constraint Optimization Problems and Applications: {A} Survey}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{61}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{623--698}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1613/jair.5565}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1613/jair.5565}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.springer.com/journal/10601" rel="external nofollow noopener" target="_blank">Constraints</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FPYD:constraints18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Accelerating exact and approximate inference for (distributed) discrete optimization with GPUs</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Enrico Pontelli, William Yeoh, and Rina Dechter</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Constraints - An International Journal</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/s10601-017-9274-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1608.05288" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Discrete optimization is a central problem in artificial intelligence. The optimization of the aggregated cost of a network of cost functions arises in a variety of problems including Weighted Constraint Programs (WCSPs), Distributed Constraint Optimization (DCOP), as well as optimization in stochastic variants such as the tasks of finding the most probable explanation (MPE) in belief networks. Inference-based algorithms are powerful techniques for solving discrete optimization problems, which can be used independently or in combination with other techniques. However, their applicability is often limited by their compute intensive nature and their space requirements. This paper proposes the design and implementation of a novel inference-based technique, which exploits modern massively parallel architectures, such as those found in Graphical Processing Units (GPUs), to speed up the resolution of exact and approximated inference-based algorithms for discrete optimization. The paper studies the proposed algorithm in both centralized and distributed optimization contexts. The paper demonstrates that the use of GPUs provides significant advantages in terms of runtime and scalability, achieving up to two orders of magnitude in speedups and showing a considerable reduction in execution time (up to 345 times faster) with respect to a sequential version.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FPYD:constraints18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Pontelli, Enrico and Yeoh, William and Dechter, Rina}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accelerating exact and approximate inference for (distributed) discrete optimization with GPUs}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Constraints - An International Journal}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--43}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10601-017-9274-1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10601-017-9274-1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">AI Matters</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FY:aimatters18" class="col-sm-8">
        <!-- Title -->
        <div class="title">AI buzzwords explained: distributed constraint optimization problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>AI Matters</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1145/3175502.3175506" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FY:aimatters18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{AI} buzzwords explained: distributed constraint optimization problems}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{AI} Matters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8--13}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3175502.3175506}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3175502.3175506}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">TPLP</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FP:tpc18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Past and present (and future) of parallel and distributed computation in (constraint) logic programming</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Theory Pract. Log. Program.</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1017/S1471068418000406" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FP:tpc18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Past and present (and future) of parallel and distributed computation in (constraint) logic programming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Theory Pract. Log. Program.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{5-6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{722--724}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1017/S1471068418000406}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1017/S1471068418000406}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FLvH:aamas18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained-Based Differential Privacy for Mobility Services</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Chansoo Lee, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=3237910" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Ubiquitous mobile and wireless communication systems have the potential to revolutionize transportation systems, making accurate mobility traces and activity-based patterns available to optimize their design and operations. It also poses significant privacy risks, potentially revealing highly sensitive personal information. This paper studies the use of differential privacy to release mobility data that can be used for smart transportation systems. It shows that existing approaches do not provide the desired fidelity for practical uses. To remedy this critical limitation, the paper proposes the idea of optimization-based differential privacy that casts the production of a private dataset as an optimization problem that minimizes the impact of added Laplacian noise on the algorithmic task at hand. When applied to a city-level multi-modal transit system, experimental results show that the design and operations of the transportation system have similar performance measures when optimized over the real and private datasets. The results also indicate that optimization-based differential privacy may improve the accuracy of state-of-art privacy methods by an order of magnitude.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FLvH:aamas18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Lee, Chansoo and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained-Based Differential Privacy for Mobility Services}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1405--1413}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{International Foundation for Autonomous Agents and Multiagent Systems Richland, SC, {USA} / {ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=3237910}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="HFWPZ:cp18" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Large Neighboring Search Schema for Multi-agent Optimization</div>
        <!-- Author -->
        <div class="author">
        

        Khoi D. Hoang, <em>Ferdinando Fioretto</em>, William Yeoh, Enrico Pontelli, and Roie Zivan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-98334-9_44" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
            <a href="http://arxiv.org/abs/1702.06915" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Distributed Constraint Optimization Problem (DCOP) is an elegant paradigm for modeling and solving multi-agent problems which are distributed in nature, and where agents cooperate to optimize a global objective within the confines of localized communication. Since solving DCOPs optimally is NP-hard, recent effort in the development of DCOP algorithms has focused on incomplete methods. Unfortunately, many of such proposals do not provide quality guarantees or provide a loose quality assessment. Thus, this paper proposes the Distributed Large Neighborhood Search (DLNS), a novel iterative local search framework to solve DCOPs, which provides guarantees on solution quality refining lower and upper bounds in an iterative process. Our experimental analysis of DCOP benchmarks on several important classes of graphs illustrates the effectiveness of DLNS in finding good solutions and tight upper bounds in both problems with and without hard constraints.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HFWPZ:cp18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Khoi D. and Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico and Zivan, Roie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Large Neighboring Search Schema for Multi-agent Optimization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11008}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{688--706}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-98334-9\_44}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-98334-9\_44}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CPAIOR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FvH:cpaior18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained-Based Differential Privacy: Releasing Optimal Power Flow
                  Benchmarks Privately - Releasing Optimal Power Flow Benchmarks Privately</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Pascal Van Hentenryck</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Integration of Constraint Programming, Artificial Intelligence, and Operations Research</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-93031-2_15" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper considers the problem of releasing optimal power flow benchmarks that maintain the privacy of customers (loads) using the notion of Differential Privacy. It is motivated by the observation that traditional differential-privacy mechanisms are not accurate enough: The dded noise fundamentally changes the nature of the underlying optimization and often leads to test cases with no solution. To remedy this limitation, the paper introduces the framework of Constraint-Based Differential Privacy (CBDP) that leverages the post-processing immunity of differential privacy to improve the accuracy of traditional mechanisms. More precisely, CBDP solves an optimization problem to satisfies the problem-specific constraints by redistributing the noise. The paper shows that CBDP enjoys desirable theoretical properties and produces orders of magnitude improvements on the largest set of test cases available.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FvH:cpaior18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Hentenryck, Pascal Van}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained-Based Differential Privacy: Releasing Optimal Power Flow
                    Benchmarks Privately - Releasing Optimal Power Flow Benchmarks Privately}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Integration of Constraint Programming, Artificial Intelligence, and Operations Research}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10848}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{215--231}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-93031-2\_15}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-93031-2\_15}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ISAIM</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FKK:isiam18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constraint Composite Graph-Based Lifted Message Passing for Distributed
                  Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Hong Xu, Sven Koenig, and T. K. Satish Kumar</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Symposium on Artificial Intelligence and Mathematics,
                  ISAIM 2018, Fort Lauderdale, Florida, USA, January 3-5, 2018</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://isaim2018.cs.virginia.edu/papers/ISAIM2018_Fioretto_etal.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p> The Distributed Constraint Optimization Problem (DCOP) offers a powerful approach for the description and resolution of cooperative multi-agent problems. In this model, a group of agents coordinates their actions to optimize a global objective function, taking into account their local preferences. In the majority of DCOP algorithms, agents operate on three main graphical representations of the problem: (a) the constraint graph, (b) the pseudo-tree, or (c) the factor graph. In this paper, we introduce the Constraint Composite Graph (CCG) for DCOPs, an alternative graphical representation on which agents can coordinate their assignments to solve the distributed problem suboptimally. By leveraging this repre- sentation, agents are able to reduce the size of the problem. We propose a novel variant of Max-Sum–a popular DCOP incomplete algorithm–called CCG-Max-Sum, which is applied to CCGs. We also demonstrate the efficiency and effective- ness of CCG-Max-Sum on DCOP benchmarks based on several network topologies.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FKK:isiam18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Xu, Hong and Koenig, Sven and Kumar, T. K. Satish}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constraint Composite Graph-Based Lifted Message Passing for Distributed
                    Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Symposium on Artificial Intelligence and Mathematics,
                    {ISAIM} 2018, Fort Lauderdale, Florida, USA, January 3-5, 2018}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PRIMA</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FHKK:prima18" class="col-sm-8">
        <!-- Title -->
        <div class="title">Solving Multiagent Constraint Optimization Problems on the Constraint Composite Graph</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Hong Xu, Sven Koenig, and T. K. Satish Kumar</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Principles and Practice of Multi-Agent Systems</em>, 2018
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-030-03098-8_7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce the Constraint Composite Graph (CCG) for Distributed Constraint Optimization Problems (DCOPs), a popular paradigm used for the description and resolution of cooperative multi-agent problems. The CCG is a novel graphical representation of DCOPs on which agents can coordinate their assignments to solve the distributed problem suboptimally. By leveraging this representation, agents are able to reduce the size of the problem. We propose a novel variant of Max- Sum—a popular DCOP incomplete algorithm—called CCG-Max-Sum, which is applied to CCGs, and demonstrate its efficiency and effectiveness on DCOP benchmarks based on several network topologies.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FHKK:prima18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Xu, Hong and Koenig, Sven and Kumar, T. K. Satish}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Solving Multiagent Constraint Optimization Problems on the Constraint Composite Graph}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Principles and Practice of Multi-Agent Systems}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11224}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{106--122}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-030-03098-8\_7}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-03098-8\_7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2017</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">AMEC</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="fioretto:amectada-17" class="col-sm-8">
        <!-- Title -->
        <div class="title">Investigation of Learning Strategies for the SPOT Broker in Power TAC</div>
        <!-- Author -->
        <div class="author">
        

        Porag Chowdhury, Russell Y. Folk, <em>Ferdinando Fioretto</em>, Christopher Kiekintveld, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Agent-Mediated Electronic Commerce. Designing Trading Strategies and Mechanisms for Electronic Markets (AMEC/TADA)</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Power TAC simulation emphasizes the strategic problems that broker agents face in managing the economics of a smart grid. The brokers must make trades in multiple markets and, to be successful, brokers must make many good predictions about future supply, demand, and prices in the wholesale and tariff markets. In this paper, we investigate the feasibility of using learning strategies to improve the performance of our broker, SPOT. Specifically, we investigate the use of decision trees and neural networks to predict the clearing price in the wholesale market and the use of reinforcement learning to learn good strategies for pricing our tariffs in the tariff market. Our preliminary results show that our learning strategies are promising ways to improve the performance of the agent for future competitions.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Visionary Workshop Paper Award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="KF0P:aamas17" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Realistic Dataset for the Smart Home Device Scheduling Problem for DCOPs</div>
        <!-- Author -->
        <div class="author">
        

        William Kluegel, Muhammad A. Iqbal, <em>Ferdinando Fioretto</em>, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAMAS 2017 Workshops, Visionary Papers, Revised Selected Papers</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Visionary Workshop Paper Award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-71679-4_9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The field of Distributed Constraint Optimization has gained momentum in recent years thanks to its ability to address various applications related to multi-agent cooperation. While techniques for solving Distributed Constraint Optimization Problems (DCOPs) are abundant and have matured substantially since the field inception, the number of DCOP realistic applications available to assess the performance of DCOP algorithms is lagging behind. To contrast this background we (i) introduce the Smart Home Device Scheduling (SHDS) problem, which describe the problem of coordinating smart devices schedules across multiple homes as a multi-agent system, (ii) detail the physical models adopted to simulate smart sensors, smart actuators, and homes’ environments, and (iii) introduce a DCOP realistic benchmark for SHDS problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KF0P:aamas17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kluegel, William and Iqbal, Muhammad A. and Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Realistic Dataset for the Smart Home Device Scheduling Problem for DCOPs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{AAMAS} 2017 Workshops, Visionary Papers, Revised Selected Papers}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10643}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{125--142}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-71679-4\_9}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-71679-4\_9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="HHF0ZY:aamas17" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infinite-Horizon Proactive Dynamic DCOPs</div>
        <!-- Author -->
        <div class="author">
        

        Khoi D. Hoang, Ping Hou, <em>Ferdinando Fioretto</em>, William Yeoh, Roie Zivan, and Makoto Yokoo</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=3091160" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool for modeling multi-agent coordination problems. Researchers have recently extended this model to Proactive Dynamic DCOPs (PD-DCOPs) to capture the inherent dynamism present in many coordination problems. The PD-DCOP formulation is a finite-horizon model that assumes a finite horizon is known a priori. It ignores changes to the problem after the horizon and is thus not guaranteed to find optimal solutions for infinite-horizon problems, which often occur in the real world. Therefore, we (i) propose the Infinite-Horizon PD-DCOP (IPD- DCOP) model, which extends PD-DCOPs to handle infinite horizons; (ii) exploit the convergence properties of Markov chains to determine the optimal solution to the problem after it has converged; (iii) propose three distributed greedy algorithms to solve IPD-DCOPs; (iv) provide theoretical quality guarantees on the new model; and (v) empirically evaluate both proactive and reactive algorithms to determine the tradeoffs between the two classes. The final contribution is important as, thus far, researchers have exclusively evaluated the two classes of algorithms in isolation. As a result, it is difficult to identify the characteristics of problems that they excel in. Our results are the first in this important direction.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HHF0ZY:aamas17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Khoi D. and Hou, Ping and Fioretto, Ferdinando and Yeoh, William and Zivan, Roie and Yokoo, Makoto}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Infinite-Horizon Proactive Dynamic DCOPs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{212--220}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=3091160}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F0P:aamas17" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Multiagent System Approach to Scheduling Devices in Smart Homes</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=3091265" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Demand-side management (DSM) in the smart grid allows customers to make autonomous decisions on their energy consumption, helping energy providers to reduce the energy peaks in load demand. The automated scheduling of smart devices in residential and commercial buildings plays a key role in DSM. Due to data privacy and user autonomy, such an approach is best implemented through distributed multi-agent systems. This paper makes the following contributions: (i) It introduces the Smart Home Device Scheduling (SHDS) problem, which formalizes the device scheduling and coordination problem across multiple smart homes as a multi-agent system; (ii) It describes a mapping of this problem to a distributed constraint optimization problem; (iii) It proposes a distributed algorithm for the SHDS problem; and (iv) It presents empirical results from a physically distributed system of Raspberry Pis, each capable of controlling smart devices through hardware interfaces, as well as larger scale synthetic experiments.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F0P:aamas17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Multiagent System Approach to Scheduling Devices in Smart Homes}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{981--989}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=3091265}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F0PMR:aamas17" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Distributed Constraint Optimization (DCOP) Approach to the Economic Dispatch with Demand Response</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, William Yeoh, Enrico Pontelli, Ye Ma, and Satishkumar J. Ranade</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=3091267" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p> With the growing complexity of the current power grid, there is an increasing need for intelligent operations coordinating energy supply and demand. A key feature of the smart grid vision is that intelligent mechanisms will coordinate the production, transmission, and consumption of energy in a distributed and reliable way. Economic Dispatch (ED) and Demand Response (DR) are two key problems that need to be solved to achieve this vision. In traditional operations, ED and DR are implemented separately, despite the strong inter-dependencies between these two problems. Therefore, we propose an integrated approach to solve the ED and DR problems that simultaneously maximizes the benefits of customers and minimizes the generation costs, and introduce an effective multi-agent-based algorithm, based on Distributed Constraint Optimization Problems (DCOPs), acting on direct control of both generators and dispatchable loads. To cope with the high complexity of the problem, our solution employs General Purpose Graphical Processing Units (GPGPUs) to speed up the computational runtime. We empirically evaluate the proposed algorithms on standard IEEE bus systems and test the stability of the proposed solution with a state-of-the-art power system simulator on the IEEE 30-bus system.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F0PMR:aamas17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico and Ma, Ye and Ranade, Satishkumar J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Distributed Constraint Optimization {(DCOP)} Approach to the Economic Dispatch with Demand Response}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{999--1007}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=3091267}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="TLFY:cp17" class="col-sm-8">
        <!-- Title -->
        <div class="title">Preference Elicitation for DCOPs</div>
        <!-- Author -->
        <div class="author">
        

        Atena M. Tabakhi, Tiep Le, <em>Ferdinando Fioretto</em>, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2017
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-66158-2_18" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Distributed Constraint Optimization Problems (DCOPs) offer a powerful approach for the description and resolution of cooperative multi-agent problems. In this model, a group of agents coordinate their actions to optimize a global objective function, taking into account their preferences or constraints. A core limitation of this model is the assumption that the preferences of all agents or the costs of all constraints are specified a priori. Unfortunately, this assumption does not hold in a number of application domains where preferences or constraints must be elicited from the users. One of such domains is the Smart Home Device Scheduling (SHDS) problem. Motivated by this limitation, we make the following contributions in this paper: (1) We propose a general model for preference elicitation in DCOPs; (2) We propose several heuristics to elicit preferences in DCOPs; and (3) We empirically evaluate the effect of these heuristics on random binary DCOPs as well as SHDS problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TLFY:cp17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tabakhi, Atena M. and Le, Tiep and Fioretto, Ferdinando and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Preference Elicitation for DCOPs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10416}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{278--296}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-66158-2\_18}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-66158-2\_18}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2016</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">PhD Thesis</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DBLP:phd/it/Fioretto16" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploiting the Structure of Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>University of Udine, Italy</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://opac.bncf.firenze.sbn.it/bncf-prod/resource?uri=TD16020931" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">DBLP:phd/it/Fioretto16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting the Structure of Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{University of Udine, Italy}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://opac.bncf.firenze.sbn.it/bncf-prod/resource?uri=TD16020931}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">AMEC/TADA</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="CFFK0:tada16" class="col-sm-8">
        <!-- Title -->
        <div class="title">Investigation of Learning Strategies for the SPOT Broker in Power TAC</div>
        <!-- Author -->
        <div class="author">
        

        Moinul Morshed Porag Chowdhury, Russell Y. Folk, <em>Ferdinando Fioretto</em>, Christopher Kiekintveld, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Agent-Mediated Electronic Commerce. Designing Trading Strategies and
                  Mechanisms for Electronic Markets - AMEC/TADA
                  Revised Selected Papers</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-54229-4_7" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CFFK0:tada16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chowdhury, Moinul Morshed Porag and Folk, Russell Y. and Fioretto, Ferdinando and Kiekintveld, Christopher and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Investigation of Learning Strategies for the {SPOT} Broker in Power {TAC}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Agent-Mediated Electronic Commerce. Designing Trading Strategies and
                    Mechanisms for Electronic Markets - {AMEC/TADA}
                    Revised Selected Papers}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Business Information Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{271}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{96--111}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-54229-4\_7}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-54229-4\_7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F0P:aaai16" class="col-sm-8">
        <!-- Title -->
        <div class="title">Multi-Variable Agents Decomposition for DCOPs</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12093" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The application of DCOP models to large problems faces two main limitations: (i) Modeling limitations, as each agent can handle only a single variable of the problem; and (ii) Resolution limitations, as current approaches do not exploit the local problem structure within each agent. This paper proposes a novel Multi-Variable Agent (MVA) DCOP decomposition technique, which: (i) Exploits the co-locality of each agent’s variables, allowing us to adopt efficient centralized techniques within each agent; (ii) Enables the use of hierarchical parallel models and proposes the use of GPUs; and (iii) Reduces the amount of computation and communication required in several classes of DCOP algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F0P:aaai16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Variable Agents Decomposition for DCOPs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2480--2486}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12093}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="HFHY0Z:aamas16" class="col-sm-8">
        <!-- Title -->
        <div class="title">Proactive Dynamic Distributed Constraint Optimization</div>
        <!-- Author -->
        <div class="author">
        

        Khoi D. Hoang, <em>Ferdinando Fioretto</em>, Ping Hou, Makoto Yokoo, William Yeoh, and Roie Zivan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2937013" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Current approaches that model dynamism in DCOPs solve a sequence of static problems, reacting to changes in the environment as the agents observe them. Such approaches thus ignore possible predictions on future changes. To overcome this limitation, we introduce Proactive Dynamic DCOPs (PD-DCOPs), a novel formalism to model dynamic DCOPs in the presence of exogenous uncertainty. In contrast to reactive approaches, PD-DCOPs are able to explicitly model the possible changes to the problem, and take such information into account proactively, when solving the dynamically changing problem. The additional expressivity of this formalism allows it to model a wider variety of distributed optimization problems. Our work presents both theoretical and practical contributions that advance current dynamic DCOP models: (i) we introduce the PD-DCOP model, which explicitly captures dynamic changes of the DCOP over time; (ii) we discuss the complexity of this new class of DCOPs; and (iii) we develop both exact and approximation algorithms with quality guarantees to solve PD-DCOPs proactively.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">HFHY0Z:aamas16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Khoi D. and Fioretto, Ferdinando and Hou, Ping and Yokoo, Makoto and Yeoh, William and Zivan, Roie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Proactive Dynamic Distributed Constraint Optimization}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{597--605}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2937013}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="LeF0SP:aamas16" class="col-sm-8">
        <!-- Title -->
        <div class="title">ER-DCOPs: A Framework for Distributed Constraint Optimization with Uncertainty in Constraint Utilities</div>
        <!-- Author -->
        <div class="author">
        

        Tiep Le, <em>Ferdinando Fioretto</em>, William Yeoh, Tran Cao Son, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2937014" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Distributed Constraint Optimization Problems (DCOPs) have been used to model a number of multi-agent coordination problems. In DCOPs, agents are assumed to have complete information about the utility of their possible actions. However, in many real-world applications, such utilities are stochastic due to the presence of exogenous events that are beyond the direct control of the agents. This paper addresses this issue by extending the standard DCOP model to Expected Regret DCOP (ER-DCOP) for DCOP applications with uncertainty in constraint utilities. Different from other approaches, ER-DCOPs aim at minimizing the overall expected regret of the problem. The paper proposes the ER-DPOP algorithm for solving ER-DCOPs, which is complete and requires a linear number of messages with respect to the number of agents in the problem. We further present two implementations of ER-DPOP—GPU- and ASP-based implementations—that orthogonally exploit the problem structure and present their evaluations on random networks and power network problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">LeF0SP:aamas16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Le, Tiep and Fioretto, Ferdinando and Yeoh, William and Son, Tran Cao and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ER-DCOPs: {A} Framework for Distributed Constraint Optimization with Uncertainty in Constraint Utilities}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{606--614}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2937014}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F0P:cp16" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Dynamic Programming-Based MCMC Framework for Solving DCOPs with GPUs</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-44953-1_51" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The field of Distributed Constraint Optimization (DCOP) has gained momentum in recent years, thanks to its ability to address various applications related to multi-agent coordination. Nevertheless, solving DCOPs is computationally challenging. Thus, in large scale, complex applications, incomplete DCOP algorithms are necessary. Recently, researchers have introduced a promising class of incomplete DCOP algorithms, based on sampling. However, this paradigm requires a multitude of samples to ensure convergence. This paper exploits the property that sampling is amenable to parallelization, and introduces a general framework, called Distributed MCMC (DMCMC), that is based on a dynamic programming procedure and uses Markov Chain Monte Carlo (MCMC) sampling algorithms to solve DCOPs. Additionally, DMCMC harnesses the parallel computing power of Graphical Processing Units (GPUs) to speed-up the sampling process. The experimental results show that DMCMC can find good solutions up to two order of magnitude faster than other incomplete DCOP algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F0P:cp16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Dynamic Programming-Based {MCMC} Framework for Solving DCOPs with GPUs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9892}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{813--831}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-44953-1\_51}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-44953-1\_51}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">AISGSB</abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/aaai/HoangFHY0Z16" class="col-sm-8">
        <!-- Title -->
        <div class="title">Proactive Dynamic DCOPs</div>
        <!-- Author -->
        <div class="author">
        

        Khoi D. Hoang, <em>Ferdinando Fioretto</em>, Ping Hou, Makoto Yokoo, William Yeoh, and Roie Zivan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AI for Smart Grids and Smart Buildings, Papers from the 2016 AAAI
                  Workshop, Phoenix, Arizona, USA, February 12, 2016</em>, 2016
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://www.aaai.org/ocs/index.php/WS/AAAIW16/paper/view/12593" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/aaai/HoangFHY0Z16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hoang, Khoi D. and Fioretto, Ferdinando and Hou, Ping and Yokoo, Makoto and Yeoh, William and Zivan, Roie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Proactive Dynamic DCOPs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{AI} for Smart Grids and Smart Buildings, Papers from the 2016 {AAAI}
                    Workshop, Phoenix, Arizona, USA, February 12, 2016}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{{AAAI} Technical Report}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{{WS-16-04}}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.aaai.org/ocs/index.php/WS/AAAIW16/paper/view/12593}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2015</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://dl.acm.org/journal/tomacs" rel="external nofollow noopener" target="_blank">TOMACS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FDP:tomacs15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constrained Community-Based Gene Regulatory Network Inference</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Agostino Dovier, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>ACM Transaction on Modeling and Computer Simulation</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1145/2688909" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The problem of gene regulatory network inference is a major concern of systems biology. In recent years, a novel methodology has gained momentum, called community network approach. Community networks integrate predictions from individual methods in a “metapredictor,” in order to compose the advantages of different methods and soften individual limitations. This article proposes a novel methodology to integrate prediction ensembles using constraint programming, a declarative modeling and problem solving paradigm. Constraint programming naturally allows the modeling of dependencies among components of the problem as constraints, facilitating the integration and use of different forms of knowledge. The new paradigm, referred to as constrained community network, uses constraints to capture properties of the regulatory networks (e.g., topological properties) and to guide the integration of knowledge derived from different families of network predictions. The article experimentally shows the potential of this approach: The addition of biological constraints can offer significant improvements in prediction accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FDP:tomacs15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Dovier, Agostino and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constrained Community-Based Gene Regulatory Network Inference}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{ACM} Transaction on Modeling and Computer Simulation}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11:1--11:26}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/2688909}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2688909}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F:aaai15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploiting the Structure of Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9293" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the proposed thesis, we study Distributed Constraint Optimization Problems (DCOPs), which are problems where several agents coordinate with each other to optimize a global cost function. The use of DCOPs has gained momentum, due to their capability of addressing complex and naturally distributed problems. A majority of the work in DCOP addresses the resolution problem by detaching the model from the resolution process, where they assume that each agent controls exclusively one variable of the problem (Burke et al. 2006). This assumption often is not reflected in the model specifications, and may lead to inefficient communication requirements. Another limitation of current DCOP resolution methods is their inability to capitalize on the presence of structural information, which may allow incoherent/unnecessary data to reticulate among the agents (Yokoo 2001). The purpose of the proposed dissertation is to study how to adapt and integrate insights gained from centralized solving techniques in order to enhance DCOP performance and scalability, enabling their use for the resolution of real-world complex problems. To do so, we hypothesize that one can exploit the DCOP structure in both problem modeling and problem resolution phases.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F:aaai15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting the Structure of Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4233}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{AAAI} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9293}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/atal/Fioretto0P15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Multi-Variable Agents Decomposition for DCOPs to Exploit Multi-Level Parallelism</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2773455" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Current DCOP algorithms suffer from a major limiting assumption—each agent can handle only a single variable of the problem—which limits their scalability. This paper proposes a novel Multi-Variable Agent (MVA) DCOP decomposition, which: (i) Exploits co-locality of an agent’s variables, allowing us to adopt efficient centralized techniques; (ii) Enables the use of hierarchical parallel models, such us those based on GPGPUs; and (iii) Empirically reduces the amount of communication required in several classes of DCOP algorithms. Experimental results show that our MVA decomposition outperforms non-decomposed DCOP algorithms, in terms of network load and scalability.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/atal/Fioretto0P15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-Variable Agents Decomposition for DCOPs to Exploit Multi-Level Parallelism}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1823--1824}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2773455}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FCDP0:aamas15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Large Neighborhood Search with Quality Guarantees for Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Federico Campeotto, Agostino Dovier, Enrico Pontelli, and William Yeoh</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2773461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper proposes Distributed Large Neighborhood Search (D-LNS), an incomplete DCOP algorithm that builds on the strengths of centralized LNS. D-LNS: (i) is anytime; (ii) provides guarantees on solution quality (upper and lower bounds); and (iii) can learn online the best neighborhood to explore. Experimental results show that D-LNS outperforms other incomplete DCOP algorithms in random and scale-free network instances.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FCDP0:aamas15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Campeotto, Federico and Dovier, Agostino and Pontelli, Enrico and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Large Neighborhood Search with Quality Guarantees for Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1835--1836}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2773461}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="F:aamas15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploiting the Structure of Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Autonomous Agents and Multiagent Systems</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2773549" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the proposed thesis, we study Distributed Constraint Optimization Problems (DCOPs), which are problems where several agents coordinate with each other to optimize a global cost function. The use of DCOPs has gained momentum, due to their capability of addressing complex and naturally distributed problems. A majority of the work in DCOP addresses the resolution problem by detaching the model from the resolution process, where they assume that each agent controls exclusively one variable of the problem (Burke et al. 2006). This assumption often is not reflected in the model specifications, and may lead to inefficient communication requirements. Another limitation of current DCOP resolution methods is their inability to capitalize on the presence of structural information, which may allow incoherent/unnecessary data to reticulate among the agents (Yokoo 2001). The purpose of the proposed dissertation is to study how to adapt and integrate insights gained from centralized solving techniques in order to enhance DCOP performance and scalability, enabling their use for the resolution of real-world complex problems. To do so, we hypothesize that one can exploit the DCOP structure in both problem modeling and problem resolution phases.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">F:aamas15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting the Structure of Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Autonomous Agents and Multiagent Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2007--2008}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2773549}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FLP0S:cp15" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploiting GPUs in Solving (Distributed) Constraint Optimization Problems with Dynamic Programming</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Tiep Le, Enrico Pontelli, William Yeoh, and Tran Cao Son</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2015
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-23219-5_9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper proposes the design and implementation of a dynamic programming based algorithm for (distributed) constraint optimization, which exploits modern massively parallel architectures, such as those found in modern Graphical Processing Units (GPUs). The paper studies the proposed algorithm in both centralized and distributed optimization contexts. The experimental analysis, performed on unstructured and structured graphs, shows the advantages of employing GPUs, resulting in enhanced performances and scalability.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FLP0S:cp15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Le, Tiep and Pontelli, Enrico and Yeoh, William and Son, Tran Cao}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Pesant, Gilles}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploiting GPUs in Solving (Distributed) Constraint Optimization Problems with Dynamic Programming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9255}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{121--139}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-23219-5\_9}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-23219-5\_9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2014</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">AAMAS</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FCF0P:aamas14" class="col-sm-8">
        <!-- Title -->
        <div class="title">GD-GIBBS: a GPU-based sampling algorithm for solving distributed constraint optimization problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Federico Campeotto, Luca Da Rin Fioretto, William Yeoh, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAMAS</em>, 2014
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dl.acm.org/citation.cfm?id=2617462" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Researchers have recently introduced a promising new class of Distributed Constraint Optimization Problem (DCOP) algorithms that is based on sampling. This paradigm is very amenable to parallelization since sampling algorithms require a lot of samples to ensure convergence, and the sampling process can be designed to be executed in parallel. This paper presents GPU-based D-Gibbs (GD-Gibbs), which extends the Distributed Gibbs (D-Gibbs) sampling algorithm and harnesses the power of parallel computation of GPUs to solve DCOPs. Experimental results show that GD-Gibbs is faster than several other benchmark algorithms on a distributed meeting scheduling problem.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FCF0P:aamas14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Campeotto, Federico and Fioretto, Luca Da Rin and Yeoh, William and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{GD-GIBBS:} a GPU-based sampling algorithm for solving distributed constraint optimization problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAMAS}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1339--1340}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{IFAAMAS/ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dl.acm.org/citation.cfm?id=2617462}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="FLYPS:cp14" class="col-sm-8">
        <!-- Title -->
        <div class="title">Improving DPOP with Branch Consistency for Solving Distributed Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, Tiep Le, William Yeoh, Enrico Pontelli, and Tran Cao Son</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In CP</em>, 2014
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-10428-7_24" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The DCOP model has gained momentum in recent years thanks to its ability to capture problems that are naturally distributed and cannot be realistically addressed in a centralized manner. Dynamic programming based techniques have been recognized to be among the most effective techniques for building complete DCOP solvers (e.g., DPOP). Unfortunately, they also suffer from a widely recognized drawback: their messages are exponential in size. Another limitation is that most current DCOP algorithms do not actively exploit hard constraints, which are common in many real problems. This paper addresses these two limitations by introducing an algorithm, called BrC-DPOP, that exploits arc consistency and a form of consistency that applies to paths in pseudo-trees to reduce the size of the messages. Experimental results shows that BrC-DPOP uses messages that are up to one order of magnitude smaller than DPOP, and that it can scale up well, being able to solve problems that its counterpart can not.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FLYPS:cp14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fioretto, Ferdinando and Le, Tiep and Yeoh, William and Pontelli, Enrico and Son, Tran Cao}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving {DPOP} with Branch Consistency for Solving Distributed Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CP}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8656}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{307--323}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-10428-7\_24}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-10428-7\_24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">ECAI</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="CDFP:ecai14" class="col-sm-8">
        <!-- Title -->
        <div class="title">A GPU Implementation of Large Neighborhood Search for Solving Constraint Optimization Problems</div>
        <!-- Author -->
        <div class="author">
        

        Federico Campeotto, Agostino Dovier, <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Artificial Intelligence</em>, 2014
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.3233/978-1-61499-419-0-189" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Constraint programming has gained prominence as an effective and declarative paradigm for modeling and solving complex combinatorial problems. Techniques based on local search have proved practical to solve real-world problems, providing a good compromise between optimality and efficiency. In spite of the natural presence of concurrency, there has been relatively limited effort to use novel massively parallel architectures, such as those found in modern Graphical Processing Units (GPUs), to speedup local search techniques in constraint programming. This paper describes a novel framework which exploits parallelism from a popular local search method (the Large Neighborhood Search method), using GPUs.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CDFP:ecai14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Campeotto, Federico and Dovier, Agostino and Fioretto, Ferdinando and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A {GPU} Implementation of Large Neighborhood Search for Solving Constraint Optimization Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Frontiers in Artificial Intelligence and Applications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{263}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{189--194}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{IOS} Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3233/978-1-61499-419-0-189}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3233/978-1-61499-419-0-189}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">PADL</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="CPDF:padlP14" class="col-sm-8">
        <!-- Title -->
        <div class="title">Exploring the Use of GPUs in Constraint Solving</div>
        <!-- Author -->
        <div class="author">
        

        Federico Campeotto, Alessandro Dal Palù, Agostino Dovier, <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Practical Aspects of Declarative Languages</em>, 2014
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://doi.org/10.1007/978-3-319-04132-2_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper presents an experimental study aimed at assessing the feasibility of parallelizing constraint propagation—with particular focus on arc-consistency—using Graphical Processing Units (GPUs). GPUs support a form of data parallelism that appears to be suitable to the type of processing required to cycle through constraints and domain values during consistency checking and propagation. The paper illustrates an implementation of a constraint solver capable of hybrid propagations (i.e., alternating CPU and GPU), and demonstrates the potential for competitiveness against sequential implementations.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CPDF:padlP14</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Campeotto, Federico and Pal{\`{u}}, Alessandro Dal and Dovier, Agostino and Fioretto, Ferdinando and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring the Use of GPUs in Constraint Solving}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Practical Aspects of Declarative Languages}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8324}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{152--167}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-04132-2\_11}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-04132-2\_11}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2013</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#004d99"><a href="https://www.jair.org/index.php/jair" rel="external nofollow noopener" target="_blank">JAIR</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="fioretto:JAIR-13" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Constraint Solver for Flexible Protein Model</div>
        <!-- Author -->
        <div class="author">
        

        Federico Campeotto, Alessandro Dal Palù, Agostino Dovier, <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2013
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1613/jair.4193" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>his paper proposes the formalization and implementation of a novel class of constraints aimed at modeling problems related to placement of multi-body systems in the 3-dimensional space. Each multi-body is a system composed of body elements, connected by joint relationships and constrained by geometric properties. The emphasis of this investigation is the use of multi-body systems to model native conformations of protein structures—where each body represents an entity of the protein (e.g., an amino acid, a small peptide) and the geometric constraints are related to the spatial properties of the composing atoms. The paper explores the use of the proposed class of constraints to support a variety of different structural analysis of proteins, such as loop modeling and structure prediction. The declarative nature of a constraint-based encoding provides elaboration tolerance and the ability to make use of any additional knowledge in the analysis studies. The filtering capabilities of the proposed constraints also allow to control the number of representative solutions that are withdrawn from the conformational space of the protein, by means of criteria driven by uniform distribution sampling principles. In this scenario it is possible to select the desired degree of precision and/or number of solutions. The filtering component automatically excludes configurations that violate the spatial and geometric properties of the composing multi-body system. The paper illustrates the implementation of a constraint solver based on the multi-body perspective and its empirical evaluation on protein structure analysis problems.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CMSB</a></abbr><!--
          <br>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best Paper Award</span>
          -->
</div>

        <!-- Entry bib key -->
        <div id="fioretto:CMSB-13" class="col-sm-8">
        <!-- Title -->
        <div class="title">Constraint Programming in Community-Based Gene Regulatory Network Inference</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Computational Methods in Systems Biology</em>, 2013
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
        </div>

        <div>
          <span class="badge danger-color-dark align-middle" style="min-width: 75px;">Best Paper Award</span>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1007/978-3-642-40708-6_11" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Gene Regulatory Network (GRN) inference is a major objective of Systems Biology. The complexity of biological systems and the lack of adequate data have posed many challenges to the inference problem. Community networks integrate predictions from individual methods in a “meta predictor”, in order to compose the advantages of different methods and soften individual limitations. This paper proposes a novel methodology to integrate prediction ensembles using Constraint Programming, a declarative modeling paradigm, which allows the formulation of dependencies among components of the problem, enabling the integration of diverse forms of knowledge. The paper experimentally shows the potential of this method: the addition of biological constraints can offer improvements in the prediction accuracy, and the method shows promising results in assessing biological hypothesis using constraints.</p>
          </div>
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2012</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:#0073e6"><a href="">CP</a></abbr><!--
          -->
</div>

        <!-- Entry bib key -->
        <div id="CPDFP:cp12" class="col-sm-8">
        <!-- Title -->
        <div class="title">A Filtering Technique for Fragment Assembly-Based Proteins Loop Modeling with Constraints</div>
        <!-- Author -->
        <div class="author">
        

        Federico Campeotto, Alessandro Dal Palù, Agostino Dovier, <em>Ferdinando Fioretto</em>, and Enrico Pontelli</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Principles and Practice of Constraint Programming</em>, 2012
        </div>
        <!-- <div class="periodical">
          
        </div> -->

        <div>
          Also appeared in  <abbr><a href="">WCB (CP 2012)</a></abbr>
        </div>

        <div>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="http://dx.doi.org/10.1007/978-3-642-33558-7_61" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Online</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Methods to predict the structure of a protein often rely on the knowledge of macro sub-structures and their exact or approximated relative positions in space. The parts connecting these sub-structures are called loops and, in general, they are characterized by a high degree of freedom. The modeling of loops is a critical problem in predicting protein conformations that are biologically realistic. This paper introduces a class of constraints that models a general multi-body system; we present a proof of NP-completeness and provide filtering techniques, inspired by inverse kinematics, that can drastically reduce the search space of potential conformations. The paper shows the application of the constraint in solving the protein loop modeling problem, based on fragments assembly.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CPDFP:cp12</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Campeotto, Federico and Pal{\`{u}}, Alessandro Dal and Dovier, Agostino and Fioretto, Ferdinando and Pontelli, Enrico}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Filtering Technique for Fragment Assembly-Based Proteins Loop Modeling with Constraints}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Principles and Practice of Constraint Programming}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{850--866}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dx.doi.org/10.1007/978-3-642-33558-7_61}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-642-33558-7_61}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

</div>

          </article>
</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Ferdinando (Nando)  Fioretto. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.
Last updated: March 31, 2025.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
